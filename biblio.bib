
@article{pfeiffer2016,
  title = {From {{Perception}} to {{Decision}}: {{A Data}}-Driven {{Approach}} to {{End}}-to-End {{Motion Planning}} for {{Autonomous Ground Robots}}},
  url = {https://arxiv.org/abs/1609.07910},
  shorttitle = {From {{Perception}} to {{Decision}}},
  timestamp = {2016-11-09T22:23:15Z},
  journaltitle = {arXiv preprint arXiv:1609.07910},
  author = {Pfeiffer, Mark and Schaeuble, Michael and Nieto, Juan and Siegwart, Roland and Cadena, Cesar},
  urldate = {2016-11-09},
  date = {2016}
}

@inproceedings{oudah2015,
  location = {{New York, NY, USA}},
  title = {Learning to {{Interact}} with a {{Human Partner}}},
  isbn = {978-1-4503-2883-8},
  url = {http://doi.acm.org/10.1145/2696454.2696482},
  doi = {10.1145/2696454.2696482},
  abstract = {Despite the importance of mutual adaption in human relationships, online learning is not yet used during most successful human-robot interactions. The lack of online learning in HRI to date can be attributed to at least two unsolved challenges: random exploration (a core component of most online-learning algorithms) and the slow convergence rates of previous online-learning algorithms. However, several recently developed online-learning algorithms have been reported to learn at much faster rates than before, which makes them candidates for use in human-robot interactions. In this paper, we explore the ability of these algorithms to learn to interact with people. Via user study, we show that these algorithms alone do not consistently learn to collaborate with human partners. Similarly, we observe that humans fail to consistently collaborate with each other in the absence of explicit communication. However, we demonstrate that one algorithm does learn to effectively collaborate with people when paired with a novel cheap-talk communication system. In addition to this technical achievement, this work highlights the need to address AI and HRI synergistically rather than independently.},
  timestamp = {2016-10-20T12:42:14Z},
  booktitle = {Proceedings of the {{Tenth Annual ACM}}/{{IEEE International Conference}} on {{Human}}-{{Robot Interaction}}},
  series = {HRI '15},
  publisher = {{ACM}},
  author = {Oudah, Mayada and Babushkin, Vahan and Chenlinangjia, Tennom and Crandall, Jacob W.},
  urldate = {2016-10-20},
  date = {2015},
  pages = {311--318},
  file = {ACM Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/44QEJ6B3/Oudah et al. - 2015 - Learning to Interact with a Human Partner.pdf:application/pdf}
}

@inproceedings{nguyen2016,
  title = {Detecting {{Object Affordances}} with {{Convolutional Neural Networks}}},
  url = {http://dkanou.github.io/publ/P9__Nguyen_Kanoulas_Caldwell_Tsagarakis__2016__Detecting_Object_Affordances_with_Convolutional_Neural_Networks.pdf},
  timestamp = {2016-11-23T10:21:43Z},
  booktitle = {{{IEEE}}/{{RSJ Int}}. {{Conf}}. on {{Intelligent Robots}} and {{Systems}}},
  author = {Nguyen, Anh and Kanoulas, Dimitrios and Caldwell, Darwin G. and Tsagarakis, Nikos G.},
  urldate = {2016-11-23},
  date = {2016}
}

@article{mnih2016,
  title = {Asynchronous {{Methods}} for {{Deep Reinforcement Learning}}},
  url = {http://arxiv.org/abs/1602.01783},
  abstract = {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.},
  timestamp = {2016-10-10T13:52:56Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1602.01783},
  primaryClass = {cs},
  author = {Mnih, Volodymyr and Badia, Adrià Puigdomènech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P. and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  urldate = {2016-10-10},
  date = {2016-02-04},
  keywords = {asynchronous learning,deep learning,deep reinforcement learning,reinforcement learning},
  file = {arXiv\:1602.01783 PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/A2R5C79K/Mnih et al. - 2016 - Asynchronous Methods for Deep Reinforcement Learni.pdf:application/pdf;arXiv.org Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/RN7S2RT3/1602.html:text/html}
}

@article{bhatnagar2009,
  title = {Natural Actor–critic Algorithms},
  volume = {45},
  url = {http://www.sciencedirect.com/science/article/pii/S0005109809003549},
  timestamp = {2016-12-01T12:29:10Z},
  number = {11},
  journaltitle = {Automatica},
  author = {Bhatnagar, Shalabh and Sutton, Richard S. and Ghavamzadeh, Mohammad and Lee, Mark},
  urldate = {2016-12-01},
  date = {2009},
  pages = {2471--2482}
}

@article{rolf2009,
  title = {Attention via Synchrony: {{Making}} Use of Multimodal Cues in Social Learning},
  volume = {1},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4815438},
  shorttitle = {Attention via Synchrony},
  timestamp = {2016-11-07T16:24:01Z},
  number = {1},
  journaltitle = {IEEE Transactions on Autonomous Mental Development},
  author = {Rolf, Matthias and Hanheide, Marc and Rohlfing, Katharina J.},
  urldate = {2016-11-07},
  date = {2009},
  pages = {55--67}
}

@inproceedings{levine2013,
  title = {Variational Policy Search via Trajectory Optimization},
  url = {http://papers.nips.cc/paper/5178-variational-policy-search-via-trajectory-optimization},
  timestamp = {2016-11-17T10:20:43Z},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Levine, Sergey and Koltun, Vladlen},
  urldate = {2016-11-17},
  date = {2013},
  pages = {207--215}
}

@article{cederborg2014,
  title = {A Social Learning Formalism for Learners Trying to Figure out What a Teacher Wants Them to Do},
  volume = {5},
  issn = {2081-4836},
  url = {http://www.degruyter.com/view/j/pjbr.2014.5.issue-1/pjbr-2014-0005/pjbr-2014-0005.xml},
  doi = {10.2478/pjbr-2014-0005},
  timestamp = {2016-10-10T15:45:36Z},
  number = {1},
  journaltitle = {Paladyn, Journal of Behavioral Robotics},
  author = {Cederborg, Thomas and Oudeyer, Pierre-Yves},
  urldate = {2016-10-10},
  date = {2014-01-14},
  keywords = {human robot interaction,interactive learning,learning theory},
  file = {Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/H6A6G7KW/Cederborg et Oudeyer - 2014 - A social learning formalism for learners trying to.pdf:application/pdf}
}

@article{austermann2010,
  title = {Teaching a Pet-Robot to Understand User Feedback through Interactive Virtual Training Tasks},
  volume = {20},
  url = {http://link.springer.com/article/10.1007/s10458-009-9095-8},
  timestamp = {2016-11-23T14:04:29Z},
  number = {1},
  journaltitle = {Autonomous agents and multi-agent systems},
  author = {Austermann, Anja and Yamada, Seiji},
  urldate = {2016-11-23},
  date = {2010},
  pages = {85--104}
}

@inproceedings{ugur2014,
  title = {Emergent Structuring of Interdependent Affordance Learning Tasks},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6983028},
  timestamp = {2016-11-13T16:58:18Z},
  booktitle = {4th {{International Conference}} on {{Development}} and {{Learning}} and on {{Epigenetic Robotics}}},
  publisher = {{IEEE}},
  author = {Ugur, Emre and Piater, Justus},
  urldate = {2016-11-13},
  date = {2014},
  pages = {489--494}
}

@inproceedings{moulin-frier2014,
  title = {Explauto: An Open-Source {{Python}} Library to Study Autonomous Exploration in Developmental Robotics},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6982976},
  shorttitle = {Explauto},
  timestamp = {2016-11-23T16:42:34Z},
  booktitle = {4th {{International Conference}} on {{Development}} and {{Learning}} and on {{Epigenetic Robotics}}},
  publisher = {{IEEE}},
  author = {Moulin-Frier, Clément and Rouanet, Pierre and Oudeyer, Pierre-Yves},
  urldate = {2016-11-23},
  date = {2014},
  pages = {171--172}
}

@article{argall2009,
  title = {A Survey of Robot Learning from Demonstration},
  volume = {57},
  url = {http://www.sciencedirect.com/science/article/pii/S0921889008001772},
  timestamp = {2016-10-31T10:40:55Z},
  number = {5},
  journaltitle = {Robotics and autonomous systems},
  author = {Argall, Brenna D. and Chernova, Sonia and Veloso, Manuela and Browning, Brett},
  urldate = {2016-10-31},
  date = {2009},
  pages = {469--483},
  file = {[PDF] researchgate.net:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/TB2J2JM7/Argall et al. - 2009 - A survey of robot learning from demonstration.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/CBWUR4H8/S0921889008001772.html:text/html}
}

@article{vollmer2014,
  title = {Robots {{Show Us How}} to {{Teach Them}}: {{Feedback}} from {{Robots Shapes Tutoring Behavior}} during {{Action Learning}}},
  volume = {9},
  issn = {1932-6203},
  url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0091349},
  doi = {10.1371/journal.pone.0091349},
  shorttitle = {Robots {{Show Us How}} to {{Teach Them}}},
  abstract = {Robot learning by imitation requires the detection of a tutor's action demonstration and its relevant parts. Current approaches implicitly assume a unidirectional transfer of knowledge from tutor to learner. The presented work challenges this predominant assumption based on an extensive user study with an autonomously interacting robot. We show that by providing feedback, a robot learner influences the human tutor's movement demonstrations in the process of action learning. We argue that the robot's feedback strongly shapes how tutors signal what is relevant to an action and thus advocate a paradigm shift in robot action learning research toward truly interactive systems learning in and benefiting from interaction.},
  timestamp = {2016-10-10T13:31:25Z},
  number = {3},
  journaltitle = {PLOS ONE},
  author = {Vollmer, Anna-Lisa and Mühlig, Manuel and Steil, Jochen J. and Pitsch, Karola and Fritsch, Jannik and Rohlfing, Katharina J. and Wrede, Britta},
  urldate = {2016-10-10},
  date = {2014-03-19},
  pages = {e91349},
  file = {Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/MD3N72JB/Vollmer et al. - 2014 - Robots Show Us How to Teach Them Feedback from Ro.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/P8JCV5I7/article.html:text/html}
}

@inproceedings{pointeau2013,
  title = {Robot Learning Rules of Games by Extraction of Intrinsic Properties},
  url = {http://www.sbri.fr/files/publications/pointeau%2013%20achi.pdf},
  timestamp = {2016-10-24T15:25:14Z},
  booktitle = {The {{Sixth International Conference}} on {{Advances}} in {{Computer}}-{{Human Interactions}}, {{ACHI}}},
  author = {Pointeau, Grégoire and Petit, Maxime and Dominey, Peter Ford},
  urldate = {2016-10-24},
  date = {2013},
  pages = {109--116},
  file = {[PDF] from sbri.fr:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/NHP8V788/Pointeau et al. - 2013 - Robot learning rules of games by extraction of int.pdf:application/pdf}
}

@article{vondrick,
  title = {Anticipating {{Visual Representations}} from {{Unlabeled Video}}},
  url = {http://www.csee.umbc.edu/~hpirsiav/papers/prediction_cvpr16.pdf},
  timestamp = {2016-11-13T16:53:31Z},
  author = {Vondrick, Carl and Pirsiavash, Hamed and Torralba, Antonio},
  urldate = {2016-11-13}
}

@inproceedings{rolf2011,
  title = {Online Goal Babbling for Rapid Bootstrapping of Inverse Models in High Dimensions},
  volume = {2},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6037368},
  timestamp = {2016-10-31T13:54:12Z},
  booktitle = {2011 {{IEEE International Conference}} on {{Development}} and {{Learning}} ({{ICDL}})},
  publisher = {{IEEE}},
  author = {Rolf, Matthias and Steil, Jochen J. and Gienger, Michael},
  urldate = {2016-10-31},
  date = {2011},
  pages = {1--8},
  file = {[PDF] uni-bielefeld.de:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/ZDMJQ3FX/Rolf et al. - 2011 - Online goal babbling for rapid bootstrapping of in.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/ZSINB4RB/6037368.html:text/html}
}

@article{pfau2016,
  title = {Connecting {{Generative Adversarial Networks}} and {{Actor}}-{{Critic Methods}}},
  url = {https://arxiv.org/abs/1610.01945},
  timestamp = {2016-11-02T13:39:29Z},
  journaltitle = {arXiv preprint arXiv:1610.01945},
  author = {Pfau, David and Vinyals, Oriol},
  urldate = {2016-11-02},
  date = {2016}
}

@inproceedings{lutkebohle2009,
  title = {The Curious Robot-Structuring Interactive Robot Learning},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5152521},
  timestamp = {2016-10-31T14:27:42Z},
  booktitle = {Robotics and {{Automation}}, 2009. {{ICRA}}'09. {{IEEE International Conference}} on},
  publisher = {{IEEE}},
  author = {Lutkebohle, Ingo and Peltason, Julia and Schillingmann, Lars and Wrede, Britta and Wachsmuth, Sven and Elbrechter, Christof and Haschke, Robert},
  urldate = {2016-10-31},
  date = {2009},
  pages = {4156--4162},
  file = {[PDF] uni-bielefeld.de:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/KGGXV9QM/Lutkebohle et al. - 2009 - The curious robot-structuring interactive robot le.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/R5Z6HS7U/5152521.html:text/html}
}

@online{zotero-null-29,
  title = {Developmental {{Robotics}}},
  url = {https://mitpress.mit.edu/books/developmental-robotics},
  abstract = {A comprehensive overview of an interdisciplinary approach to robotics that takes direct inspiration from the developmental and learning phenomena observed in children’s cognitive development.},
  timestamp = {2016-10-10T13:53:20Z},
  journaltitle = {MIT Press},
  urldate = {2016-10-10},
  keywords = {developmental robotics},
  file = {MIT.Press.Devel.Sep.2015.ISBN.0262028018.pdf:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/53CCXITK/MIT.Press.Devel.Sep.2015.ISBN.0262028018.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/HRFGFQES/developmental-robotics.html:text/html}
}

@article{baranes2013,
  title = {Active Learning of Inverse Models with Intrinsically Motivated Goal Exploration in Robots},
  volume = {61},
  url = {http://www.sciencedirect.com/science/article/pii/S0921889012000644},
  timestamp = {2016-12-02T10:24:30Z},
  number = {1},
  journaltitle = {Robotics and Autonomous Systems},
  author = {Baranes, Adrien and Oudeyer, Pierre-Yves},
  urldate = {2016-12-02},
  date = {2013},
  pages = {49--73}
}

@inproceedings{maeda2014,
  title = {Learning Interaction for Collaborative Tasks with Probabilistic Movement Primitives},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7041413},
  timestamp = {2016-11-07T16:50:09Z},
  booktitle = {2014 {{IEEE}}-{{RAS International Conference}} on {{Humanoid Robots}}},
  publisher = {{IEEE}},
  author = {Maeda, Guilherme and Ewerton, Marco and Lioutikov, Rudolf and Amor, Heni Ben and Peters, Jan and Neumann, Gerhard},
  urldate = {2016-11-07},
  date = {2014},
  pages = {527--534}
}

@article{rohlfing2016,
  title = {An {{Alternative}} to {{Mapping}} a {{Word}} onto a {{Concept}} in {{Language Acquisition}}: {{Pragmatic Frames}}},
  url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2016.00470/full},
  doi = {10.3389/fpsyg.2016.00470},
  shorttitle = {An {{Alternative}} to {{Mapping}} a {{Word}} onto a {{Concept}} in {{Language Acquisition}}},
  abstract = {The classic mapping metaphor posits that children learn a word by mapping it onto a concept of an object or event. However, we believe that a mapping metaphor cannot account for word learning, because even though children focus attention on objects, they do not necessarily remember the connection between the word and the referent unless it is framed pragmatically, that is, within a task. Our theoretical paper proposes an alternative mechanism for word learning. Our main premise is that word learning occurs as children accomplish a goal in cooperation with a partner. We follow Bruner’s (1983) idea and further specify pragmatic frames as the learning units that drive language acquisition and cognitive development. These units consist of a sequence of actions and verbal behaviors that are co-constructed with a partner to achieve a joint goal. We elaborate on this alternative, offer some initial parametrizations of the concept, and embed it in current language learning approaches.},
  timestamp = {2016-10-20T10:24:44Z},
  journaltitle = {Front. Psychol.},
  author = {Rohlfing, Katharina J. and Wrede, Britta and Vollmer, Anna-Lisa and Oudeyer, Pierre-Yves},
  urldate = {2016-10-20},
  date = {2016},
  pages = {470},
  file = {Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/TWKKSPI2/Rohlfing et al. - 2016 - An Alternative to Mapping a Word onto a Concept in.pdf:application/pdf}
}

@article{macglashan,
  title = {Convergent {{Actor Critic}} by {{Humans}}},
  url = {http://irll.eecs.wsu.edu/wp-content/papercite-data/pdf/2016iros-hrc-macglashan.pdf},
  timestamp = {2016-11-09T17:32:23Z},
  author = {MacGlashan, James and Littman, Michael L. and Roberts, David L. and Loftin, Robert and Peng, Bei and Taylor, Matthew E.},
  urldate = {2016-11-09},
  file = {[PDF] wsu.edu:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/3G6Z3U8F/MacGlashan et al. - Convergent Actor Critic by Humans.pdf:application/pdf}
}

@article{jordan2004,
  title = {Learning in Graphical Models},
  volume = {19},
  abstract = {Statistical applications in fields such as bioinformatics, information retrieval, speech processing, image processing and communications often involve large-scale models in which thousands or millions of random variables are linked in complex ways. Graphical models provide a general methodology for approaching these problems, and indeed many of the models developed by researchers in these applied fields are instances of the general graphical model formalism. We review some of the basic ideas underlying graphical models, including the algorithmic ideas that allow graphical models to be deployed in large-scale data analysis problems. We also present examples of graphical models in bioinformatics, error-control coding and language processing.},
  timestamp = {2016-10-31T12:40:55Z},
  number = {1},
  journaltitle = {Statistical Science},
  author = {Jordan, Michael I.},
  date = {2004},
  pages = {140--155},
  file = {Citeseer - Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/DF2TCNTI/Jordan - 2004 - Learning in graphical models.pdf:application/pdf;Citeseer - Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/DRQC36C2/summary.html:text/html}
}

@article{cakmak2010,
  title = {Designing {{Interactions}} for {{Robot Active Learners}}},
  volume = {2},
  issn = {1943-0604},
  doi = {10.1109/TAMD.2010.2051030},
  abstract = {This paper addresses some of the problems that arise when applying active learning to the context of human-robot interaction (HRI). Active learning is an attractive strategy for robot learners because it has the potential to improve the accuracy and the speed of learning, but it can cause issues from an interaction perspective. Here we present three interaction modes that enable a robot to use active learning queries. The three modes differ in when they make queries: the first makes a query every turn, the second makes a query only under certain conditions, and the third makes a query only when explicitly requested by the teacher. We conduct an experiment in which 24 human subjects teach concepts to our upper-torso humanoid robot, Simon, in each interaction mode, and we compare these modes against a baseline mode using only passive supervised learning. We report results from both a learning and an interaction perspective. The data show that the three modes using active learning are preferable to the mode using passive supervised learning both in terms of performance and human subject preference, but each mode has advantages and disadvantages. Based on our results, we lay out several guidelines that can inform the design of future robotic systems that use active learning in an HRI setting.},
  timestamp = {2016-10-20T12:48:21Z},
  number = {2},
  journaltitle = {IEEE Transactions on Autonomous Mental Development},
  author = {Cakmak, M. and Chao, C. and Thomaz, A. L.},
  date = {2010-06},
  pages = {108--118},
  file = {IEEE Xplore Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/A455WEFD/Cakmak et al. - 2010 - Designing Interactions for Robot Active Learners.pdf:application/pdf;IEEE Xplore Abstract Record:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/3M5BTRFK/5471105.html:text/html}
}

@inproceedings{cederborg2015,
  location = {{Buenos Aires, Argentina}},
  title = {Policy {{Shaping}} with {{Human Teachers}}},
  isbn = {978-1-57735-738-4},
  url = {http://dl.acm.org/citation.cfm?id=2832581.2832718},
  abstract = {In this work we evaluate the performance of a policy shaping algorithm using 26 human teachers. We examine if the algorithm is suitable for human-generated data on two different boards in a pac-man domain, comparing performance to an oracle that provides critique based on one known winning policy. Perhaps surprisingly, we show that the data generated by our 26 participants yields even better performance for the agent than data generated by the oracle. This might be because humans do not discourage exploring multiple winning policies. Additionally, we evaluate the impact of different verbal instructions, and different interpretations of silence, finding that the usefulness of data is affected both by what instructions is given to teachers, and how the data is interpreted.},
  timestamp = {2016-10-13T12:33:42Z},
  booktitle = {Proceedings of the 24th {{International Conference}} on {{Artificial Intelligence}}},
  series = {IJCAI'15},
  publisher = {{AAAI Press}},
  author = {Cederborg, Thomas and Grover, Ishaan and Isbell, Charles L. and Thomaz, Andrea L.},
  urldate = {2016-10-13},
  date = {2015},
  pages = {3366--3372},
  keywords = {interactive learning,reinforcement learning},
  file = {policy shaping.pdf:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/4A9HN6MZ/policy shaping.pdf:application/pdf}
}

@online{zotero-null-37,
  title = {From {{Motor Learning}} to {{Interaction Learning}} in {{Robots}}},
  url = {http://is.tuebingen.mpg.de/fileadmin/user_upload/files/publications/JNRR2009-Sigaud_[0].pdf},
  timestamp = {2016-10-27T15:48:51Z},
  urldate = {2016-10-20},
  file = {From Motor Learning to Interaction Learning in Robots:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/MS7SBS88/JNRR2009-Sigaud_[0].pdf:application/pdf}
}

@article{vinciarelli2012,
  title = {Bridging the {{Gap Between Social Animal}} and {{Unsocial Machine}}: {{A Survey}} of {{Social Signal Processing}}},
  volume = {3},
  issn = {1949-3045},
  url = {http://dx.doi.org/10.1109/T-AFFC.2011.27},
  doi = {10.1109/T-AFFC.2011.27},
  shorttitle = {Bridging the {{Gap Between Social Animal}} and {{Unsocial Machine}}},
  abstract = {Social Signal Processing is the research domain aimed at bridging the social intelligence gap between humans and machines. This paper is the first survey of the domain that jointly considers its three major aspects, namely, modeling, analysis, and synthesis of social behavior. Modeling investigates laws and principles underlying social interaction, analysis explores approaches for automatic understanding of social exchanges recorded with different sensors, and synthesis studies techniques for the generation of social behavior via various forms of embodiment. For each of the above aspects, the paper includes an extensive survey of the literature, points to the most important publicly available resources, and outlines the most fundamental challenges ahead.},
  timestamp = {2016-10-13T13:16:19Z},
  number = {1},
  journaltitle = {IEEE Trans. Affect. Comput.},
  author = {Vinciarelli, Alessandro and Pantic, Maja and Heylen, Dirk and Pelachaud, Catherine and Poggi, Isabella and D'Errico, Francesca and Schroeder, Marc},
  urldate = {2016-10-13},
  date = {2012-01},
  pages = {69--87},
  keywords = {human robot interaction,social robots},
  file = {bridgingTheGap.pdf:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/286XI6FF/bridgingTheGap.pdf:application/pdf}
}

@inproceedings{thomaz2006,
  location = {{Boston, Massachusetts}},
  title = {Reinforcement {{Learning}} with {{Human Teachers}}: {{Evidence}} of {{Feedback}} and {{Guidance}} with {{Implications}} for {{Learning Performance}}},
  isbn = {978-1-57735-281-5},
  url = {http://dl.acm.org/citation.cfm?id=1597538.1597696},
  shorttitle = {Reinforcement {{Learning}} with {{Human Teachers}}},
  abstract = {As robots become a mass consumer product, they will need to learn new skills by interacting with typical human users. Past approaches have adapted reinforcement learning (RL) to accept a human reward signal; however, we question the implicit assumption that people shall only want to give the learner feedback on its past actions. We present findings from a human user study showing that people use the reward signal not only to provide feedback about past actions, but also to provide future directed rewards to guide subsequent actions. Given this, we made specific modifications to the simulated RL robot to incorporate guidance. We then analyze and evaluate its learning performance in a second user study, and we report significant improvements on several measures. This work demonstrates the importance of understanding the human-teacher/robot-learner system as a whole in order to design algorithms that support how people want to teach while simultaneously improving the robot's learning performance.},
  timestamp = {2016-10-10T13:54:55Z},
  booktitle = {Proceedings of the 21st {{National Conference}} on {{Artificial Intelligence}} - {{Volume}} 1},
  series = {AAAI'06},
  publisher = {{AAAI Press}},
  author = {Thomaz, Andrea L. and Breazeal, Cynthia},
  urldate = {2016-10-10},
  date = {2006},
  pages = {1000--1005},
  file = {Thomaz-etal-AAAI-06.pdf:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/W44T3AHH/Thomaz-etal-AAAI-06.pdf:application/pdf}
}

@article{tagniguchi2015,
  title = {Multimodal {{Hierarchical Dirichlet Process}}-Based {{Active Perception}}},
  url = {https://pdfs.semanticscholar.org/3298/0a97cdab6d019299d055a685c0ffe24dd4d9.pdf},
  timestamp = {2016-11-25T11:01:40Z},
  journaltitle = {arXiv preprint arXiv:1510.00331},
  author = {Tagniguchi, T. and Takano, Toshiaki and Yoshino, Ryo},
  urldate = {2016-11-25},
  date = {2015}
}

@article{sigaud2016,
  title = {Towards {{Deep Developmental Learning}}},
  volume = {8},
  issn = {2379-8920},
  doi = {10.1109/TAMD.2015.2496248},
  abstract = {Deep learning techniques are having an undeniable impact on general pattern recognition issues. In this paper, from a developmental robotics perspective, we scrutinize deep learning techniques under the light of their capability to construct a hierarchy of meaningful multimodal representations from the raw sensors of robots. These investigations reveal the differences between the methodological constraints of pattern recognition and those of developmental robotics. In particular, we outline the necessity to rely on unsupervised rather than supervised learning methods and we highlight the need for progress towards the implementation of hierarchical predictive processing capabilities. Based on these new tools, we outline the emergence of a new domain that we call deep developmental learning.},
  timestamp = {2016-10-10T13:33:57Z},
  number = {2},
  journaltitle = {IEEE Transactions on Cognitive and Developmental Systems},
  author = {Sigaud, O. and Droniou, A.},
  date = {2016-06},
  pages = {99--114},
  keywords = {deep developmental learning},
  file = {IEEE Xplore Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/4XSTK9J3/Sigaud et Droniou - 2016 - Towards Deep Developmental Learning.pdf:application/pdf;IEEE Xplore Abstract Record:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/3EQESUQE/7312936.html:text/html}
}

@inproceedings{baker2011,
  title = {Bayesian Theory of Mind: {{Modeling}} Joint Belief-Desire Attribution},
  url = {http://mindmodeling.org/cogsci2011/papers/0583/paper0583.pdf},
  shorttitle = {Bayesian Theory of Mind},
  timestamp = {2016-12-13T14:37:06Z},
  booktitle = {Proceedings of the Thirty-Second Annual Conference of the Cognitive Science Society},
  author = {Baker, Chris L. and Saxe, Rebecca R. and Tenenbaum, Joshua B.},
  urldate = {2016-12-13},
  date = {2011},
  pages = {2469--2474}
}

@thesis{murphy2002,
  title = {Dynamic Bayesian Networks: Representation, Inference and Learning},
  url = {http://cs.ubc.ca/~murphyk/Thesis/thesis.pdf},
  shorttitle = {Dynamic Bayesian Networks},
  timestamp = {2016-10-31T13:08:37Z},
  institution = {{University of California, Berkeley}},
  author = {Murphy, Kevin Patrick},
  urldate = {2016-10-31},
  date = {2002},
  file = {[PDF] ubc.ca:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/BJTPSWR7/Murphy - 2002 - Dynamic bayesian networks representation, inferen.pdf:application/pdf}
}

@article{dominey2011,
  title = {The Basis of Shared Intentions in Human and Robot Cognition},
  volume = {29},
  issn = {0732-118X},
  url = {http://www.sciencedirect.com/science/article/pii/S0732118X09000373},
  doi = {10.1016/j.newideapsych.2009.07.006},
  abstract = {There is a fundamental difference between robots that are equipped with sensory, motor and cognitive capabilities, vs. simulations or non-embodied cognitive systems. Via their perceptual and motor capabilities, these robotic systems can interact with humans in an increasingly more “natural” way, physically interacting with shared objects in cooperative action settings. Indeed, such cognitive robotic systems provide a unique opportunity to developmental psychologists for implementing their theories and testing their hypotheses on systems that are becoming increasingly “at home” in the sensory--motor and social worlds, where such hypotheses are relevant. The current research is the result of interaction between research in computational neuroscience and robotics on the one hand, and developmental psychology on the other. One of the key findings in the developmental psychology context is that with respect to other primates, humans appear to have a unique ability and motivation to share goals and intentions with others. This ability is expressed in cooperative behavior very early in life, and appears to be the basis for subsequent development of social cognition. Here we attempt to identify a set of core functional elements of cooperative behavior and the corresponding shared intentional representations. We then begin to specify how these capabilities can be implemented in a robotic system, the Cooperator, and tested in human–robot interaction experiments. Based on the results of these experiments we discuss the mutual benefit for both fields of the interaction between robotics and developmental psychology.},
  timestamp = {2016-10-27T15:56:55Z},
  number = {3},
  journaltitle = {New Ideas in Psychology},
  series = {Special Issue: Cognitive Robotics and Reevaluation of Piaget Concept of Egocentrism},
  author = {Dominey, Peter Ford and Warneken, Felix},
  urldate = {2016-10-20},
  date = {2011-12},
  pages = {260--274},
  file = {[PDF] from psu.edu:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/532QVIAV/Dominey et Warneken - 2011 - The basis of shared intentions in human and robot .pdf:application/pdf;ScienceDirect Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/P6267KDS/Dominey et Warneken - 2011 - The basis of shared intentions in human and robot .pdf:application/pdf;ScienceDirect Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/PQDF5XNR/S0732118X09000373.html:text/html;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/ZUNP6PUC/S0732118X09000373.html:text/html}
}

@inproceedings{loftin2014,
  title = {Learning Something from Nothing: {{Leveraging}} Implicit Human Feedback Strategies},
  isbn = {978-1-4799-6765-0 978-1-4799-6763-6},
  url = {http://ieeexplore.ieee.org/document/6926319/},
  doi = {10.1109/ROMAN.2014.6926319},
  shorttitle = {Learning Something from Nothing},
  timestamp = {2016-10-20T08:04:59Z},
  publisher = {{IEEE}},
  author = {Loftin, Robert and Peng, Bei and MacGlashan, James and Littman, Michael L. and Taylor, Matthew E. and Huang, Jeff and Roberts, David L.},
  urldate = {2016-10-20},
  date = {2014-08},
  pages = {607--612},
  file = {Final_HumanFeedback_ROMAN14.pdf:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/XCK9H5W5/Final_HumanFeedback_ROMAN14.pdf:application/pdf}
}

@article{langkvist2014,
  title = {A Review of Unsupervised Feature Learning and Deep Learning for Time-Series Modeling},
  volume = {42},
  url = {http://www.sciencedirect.com/science/article/pii/S0167865514000221},
  timestamp = {2016-11-10T08:34:35Z},
  journaltitle = {Pattern Recognition Letters},
  author = {Längkvist, Martin and Karlsson, Lars and Loutfi, Amy},
  urldate = {2016-11-10},
  date = {2014},
  pages = {11--24}
}

@article{rolf2014,
  title = {Where Do Goals Come from? {{A}} Generic Approach to Autonomous Goal-System Development},
  url = {http://arxiv.org/abs/1410.5557},
  shorttitle = {Where Do Goals Come From?},
  timestamp = {2016-12-05T17:39:27Z},
  journaltitle = {arXiv preprint arXiv:1410.5557},
  author = {Rolf, Matthias and Asada, Minoru},
  urldate = {2016-12-05},
  date = {2014}
}

@book{steels2008,
  location = {{Oxford}},
  title = {Spatial {{Language}} and {{Dialogue}}},
  timestamp = {2016-10-20T11:50:39Z},
  publisher = {{Oxford University Press}},
  author = {Steels, Luc and Loetzsch, Martin},
  date = {2008},
  file = {steels-08c.pdf:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/WR4F4787/steels-08c.pdf:application/pdf;Perspective Alignment in Spatial Language | VUB Artificial Intelligence Lab:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/BPRKZ8MC/93.html:text/html}
}

@inproceedings{fern2010,
  title = {A Computational Decision Theory for Interactive Assistants},
  url = {http://papers.nips.cc/paper/4052-a-computational-decision-theory-for-interactive-assistants},
  timestamp = {2016-12-20T16:16:58Z},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Fern, Alan and Tadepalli, Prasad},
  urldate = {2016-12-20},
  date = {2010},
  pages = {577--585}
}

@online{zotero-null-51,
  url = {https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf},
  timestamp = {2016-11-21T09:54:03Z},
  urldate = {2016-11-21}
}

@article{kording2004,
  title = {Bayesian Integration in Sensorimotor Learning},
  volume = {427},
  url = {http://www.nature.com/nature/journal/v427/n6971/abs/nature02169.html},
  timestamp = {2016-10-31T14:19:43Z},
  number = {6971},
  journaltitle = {Nature},
  author = {Körding, Konrad P. and Wolpert, Daniel M.},
  urldate = {2016-10-31},
  date = {2004},
  pages = {244--247},
  file = {Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/DN54TR4H/nature02169.html:text/html;[HTML] nature.com:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/HGG5J7WC/nature02169.html:text/html}
}

@inproceedings{lopes2011,
  title = {Simultaneous Acquisition of Task and Feedback Models},
  volume = {2},
  doi = {10.1109/DEVLRN.2011.6037359},
  abstract = {We present a system to learn task representations from ambiguous feedback. We consider an inverse reinforcement learner that receives feedback from a teacher with an unknown and noisy protocol. The system needs to estimate simultaneously what the task is (i.e. how to find a compact representation to the task goal), and how the teacher is providing the feedback. We further explore the problem of ambiguous protocols by considering that the words used by the teacher have an unknown relation with the action and meaning expected by the robot. This allows the system to start with a set of known signs and learn the meaning of new ones. We present computational results that show that it is possible to learn the task under a noisy and ambiguous feedback. Using an active learning approach, the system is able to reduce the length of the training period.},
  eventtitle = {2011 IEEE International Conference on Development and Learning (ICDL)},
  timestamp = {2016-10-20T11:53:56Z},
  booktitle = {2011 {{IEEE International Conference}} on {{Development}} and {{Learning}} ({{ICDL}})},
  author = {Lopes, M. and Cederbourg, T. and Oudeyer, P. Y.},
  date = {2011-08},
  pages = {1--7},
  file = {IEEE Xplore Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/4V5RH7EM/Lopes et al. - 2011 - Simultaneous acquisition of task and feedback mode.pdf:application/pdf;IEEE Xplore Abstract Record:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/SI9CFSJV/6037359.html:text/html}
}

@article{coborus2013,
  title = {Leveraging Attention Focus for Effective Reinforcement Learning in Complex Domains},
  url = {https://smartech.gatech.edu/handle/1853/47618},
  timestamp = {2016-12-07T15:59:51Z},
  author = {Cobo Rus, Luis Carlos},
  urldate = {2016-12-07},
  date = {2013},
  file = {Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/KKGJ9QHW/47618.html:text/html}
}

@article{nguyen2014,
  title = {Socially Guided Intrinsic Motivation for Robot Learning of Motor Skills},
  volume = {36},
  url = {http://link.springer.com/article/10.1007/s10514-013-9339-y},
  timestamp = {2016-11-13T17:13:43Z},
  number = {3},
  journaltitle = {Autonomous Robots},
  author = {Nguyen, Sao Mai and Oudeyer, Pierre-Yves},
  urldate = {2016-11-13},
  date = {2014},
  pages = {273--294}
}

@online{zotero-null-55,
  title = {Learning to {{Interact}} and {{Interacting}} to {{Learn}}: {{Active Statistical Learning}} in {{Human}}-{{Robot Interaction}}},
  url = {http://www.indiana.edu/~dll/papers/ijcnn14.pdf},
  timestamp = {2016-10-28T08:19:18Z},
  urldate = {2016-10-20},
  file = {Learning to Interact and Interacting to Learn\: Active Statistical Learning in Human-Robot Interaction:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/EGBS597N/ijcnn14.pdf:application/pdf}
}

@article{pointeau2014,
  title = {Successive {{Developmental Levels}} of {{Autobiographical Memory}} for {{Learning Through Social Interaction}}},
  volume = {6},
  issn = {1943-0604},
  doi = {10.1109/TAMD.2014.2307342},
  abstract = {A developing cognitive system will ideally acquire knowledge of its interaction in the world, and will be able to use that knowledge to construct a scaffolding for progressively structured levels of behavior. The current research implements and tests an autobiographical memory system by which a humanoid robot, the iCub, can accumulate its experience in interacting with humans, and extract regularities that characterize this experience. This knowledge is then used in order to form composite representations of common experiences. We first apply this to the development of knowledge of spatial locations, and relations between objects in space. We then demonstrate how this can be extended to temporal relations between events, including “before” and “after,” which structure the occurrence of events in time. In the system, after extended sessions of interaction with a human, the resulting accumulated experience is processed in an offline manner, in a form of consolidation, during which common elements of different experiences are generalized in order to generate new meanings. These learned meanings then form the basis for simple behaviors that, when encoded in the autobiographical memory, can form the basis for memories of shared experiences with the human, and which can then be reused as a form of game playing or shared plan execution.},
  timestamp = {2016-10-24T15:21:01Z},
  number = {3},
  journaltitle = {IEEE Transactions on Autonomous Mental Development},
  author = {Pointeau, G. and Petit, M. and Dominey, P. F.},
  date = {2014-09},
  pages = {200--212},
  file = {IEEE Xplore Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/UWTTFHID/Pointeau et al. - 2014 - Successive Developmental Levels of Autobiographica.pdf:application/pdf;IEEE Xplore Abstract Record:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/8WR7B7E6/6784467.html:text/html}
}

@article{rezende2016,
  title = {One-{{Shot Generalization}} in {{Deep Generative Models}}},
  url = {http://arxiv.org/abs/1603.05106},
  timestamp = {2016-11-07T17:29:51Z},
  journaltitle = {arXiv preprint arXiv:1603.05106},
  author = {Rezende, Danilo Jimenez and Mohamed, Shakir and Danihelka, Ivo and Gregor, Karol and Wierstra, Daan},
  urldate = {2016-11-07},
  date = {2016}
}

@article{macglashana,
  title = {Convergent {{Actor Critic}} by {{Humans}}},
  url = {http://irll.eecs.wsu.edu/wp-content/papercite-data/pdf/2016iros-hrc-macglashan.pdf},
  timestamp = {2016-12-01T12:27:30Z},
  author = {MacGlashan, James and Littman, Michael L. and Roberts, David L. and Loftin, Robert and Peng, Bei and Taylor, Matthew E.},
  urldate = {2016-12-01}
}

@inproceedings{baranes2010,
  title = {Intrinsically Motivated Goal Exploration for Active Motor Learning in Robots: {{A}} Case Study},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5651385},
  shorttitle = {Intrinsically Motivated Goal Exploration for Active Motor Learning in Robots},
  timestamp = {2016-10-31T13:53:02Z},
  booktitle = {Intelligent {{Robots}} and {{Systems}} ({{IROS}}), 2010 {{IEEE}}/{{RSJ International Conference}} on},
  publisher = {{IEEE}},
  author = {Baranes, Adrien and Oudeyer, Pierre-Yves},
  urldate = {2016-10-31},
  date = {2010},
  pages = {1766--1773},
  file = {[PDF] archives-ouvertes.fr:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/RWZR4WCF/Baranes et Oudeyer - 2010 - Intrinsically motivated goal exploration for activ.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/3U2U8F98/5651385.html:text/html}
}

@article{chao2016,
  title = {Timed {{Petri}} Nets for Fluent Turn-Taking over Multimodal Interaction Resources in Human-Robot Collaboration},
  issn = {0278-3649, 1741-3176},
  url = {http://ijr.sagepub.com/content/early/2016/03/09/0278364915627291},
  doi = {10.1177/0278364915627291},
  abstract = {The goal of this work is to develop computational models of social intelligence that enable robots to work side by side with humans, solving problems and achieving task goals through dialogue and collaborative manipulation. A defining problem of collaborative behavior in an embodied setting is the manner in which multiple agents make use of shared resources. In a situated dialogue, these resources include physical bottlenecks such as objects or spatial regions, and cognitive bottlenecks such as the speaking floor. For a robot to function as an effective collaborative partner with a human, it must be able to seize and yield such resources appropriately according to social expectations. We describe a general framework that uses timed Petri nets for the modeling and execution of robot speech, gaze, gesture, and manipulation for collaboration. The system dynamically monitors resource requirements and availability to control real-time turn-taking decisions over resources that are shared with humans, reasoning about different resource types independently. We evaluate our approach with an experiment in which our robot Simon performs a collaborative assembly task with 26 different human partners, showing that the multimodal reciprocal approach results in superior task performance, fluency, and balance of control.},
  timestamp = {2016-11-07T15:03:07Z},
  langid = {english},
  journaltitle = {The International Journal of Robotics Research},
  author = {Chao, Crystal and Thomaz, Andrea},
  urldate = {2016-11-07},
  date = {2016-03-10},
  pages = {0278364915627291},
  keywords = {behavior architecture,collaborative discourse,collaborative manipulation,human-robot collaboration,human-robot interaction,joint action,situated dialogue,social interaction,timed Petri nets,Turn-taking}
}

@inproceedings{hasnain2012,
  title = {Synchrony as a Tool to Establish Focus of Attention for Autonomous Robots},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6385912},
  timestamp = {2016-11-07T16:28:18Z},
  booktitle = {2012 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  publisher = {{IEEE}},
  author = {Hasnain, Syed Khursheed and Gaussier, Philippe and Mostafaoui, Ghiles},
  urldate = {2016-11-07},
  date = {2012},
  pages = {2423--2428}
}

@inproceedings{moulin-frier2014a,
  title = {Explauto: An Open-Source {{Python}} Library to Study Autonomous Exploration in Developmental Robotics},
  url = {https://hal.inria.fr/hal-01061708/document},
  shorttitle = {Explauto},
  abstract = {We present an open-source Python library, called Explauto, providing a unified API to design and compare various exploration strategies driving various sensorimotor learning algorithms in various simulated or robotics systems. Explauto aims at being collaborative and pedagogic, providing a platform to developmental roboticists where they can publish and compare their algorithmic contributions related to autonomous exploration and learning, as well as a platform for teaching and scientific diffusion. The library is available at this address: https://github.com/flowersteam/explauto},
  eventtitle = {ICDL-Epirob - International Conference on Development and Learning, Epirob},
  timestamp = {2016-11-07T17:38:52Z},
  langid = {english},
  author = {Moulin-Frier, Clément and Rouanet, Pierre and Oudeyer, Pierre-Yves},
  urldate = {2016-11-07},
  date = {2014-10-13}
}

@article{antunes,
  title = {Robotic Tool Use and Problem Solving Based on Probabilistic Planning and Learned Affordances},
  url = {http://vislab.isr.ist.utl.pt/wp-content/uploads/2015/11/antunes_IROS_2015_ws_affordances.pdf},
  timestamp = {2016-12-02T16:58:45Z},
  author = {Antunes, Alexandre and Saponaro, Giovanni and Dehban, Atabak and Jamone, Lorenzo and Ventura, Rodrigo and Bernardino, Alexandre and Santos-Victor, José},
  urldate = {2016-12-02}
}

@article{begum2011,
  title = {Visual Attention for Robotic Cognition: A Survey},
  volume = {3},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5659891},
  shorttitle = {Visual Attention for Robotic Cognition},
  timestamp = {2016-11-07T17:02:21Z},
  number = {1},
  journaltitle = {IEEE Transactions on Autonomous Mental Development},
  author = {Begum, Momotaz and Karray, Fakhri},
  urldate = {2016-11-07},
  date = {2011},
  pages = {92--105}
}

@article{lotter2015,
  title = {Unsupervised {{Learning}} of {{Visual Structure}} Using {{Predictive Generative Networks}}},
  url = {http://arxiv.org/abs/1511.06380},
  timestamp = {2016-11-14T23:08:07Z},
  journaltitle = {arXiv preprint arXiv:1511.06380},
  author = {Lotter, William and Kreiman, Gabriel and Cox, David},
  urldate = {2016-11-14},
  date = {2015}
}

@inproceedings{najar2015,
  title = {Socially Guided {{XCS}}: Using Teaching Signals to Boost Learning},
  url = {http://dl.acm.org/citation.cfm?id=2768452},
  shorttitle = {Socially Guided {{XCS}}},
  timestamp = {2016-11-02T10:50:51Z},
  booktitle = {Proceedings of the {{Companion Publication}} of the 2015 {{Annual Conference}} on {{Genetic}} and {{Evolutionary Computation}}},
  publisher = {{ACM}},
  author = {Najar, Anis and Sigaud, Olivier and Chetouani, Mohamed},
  urldate = {2016-11-02},
  date = {2015},
  pages = {1021--1028}
}

@inproceedings{wang2015,
  title = {Visual Tracking with Fully Convolutional Networks},
  url = {http://www.cv-foundation.org/openaccess/content_iccv_2015/html/Wang_Visual_Tracking_With_ICCV_2015_paper.html},
  timestamp = {2016-11-13T21:10:25Z},
  booktitle = {Proceedings of the {{IEEE International Conference}} on {{Computer Vision}}},
  author = {Wang, Lijun and Ouyang, Wanli and Wang, Xiaogang and Lu, Huchuan},
  urldate = {2016-11-13},
  date = {2015},
  pages = {3119--3127}
}

@article{tenenbaum2006,
  title = {Theory-Based {{Bayesian}} Models of Inductive Learning and Reasoning},
  volume = {10},
  url = {http://www.sciencedirect.com/science/article/pii/S1364661306001343},
  timestamp = {2016-10-31T12:58:49Z},
  number = {7},
  journaltitle = {Trends in cognitive sciences},
  author = {Tenenbaum, Joshua B. and Griffiths, Thomas L. and Kemp, Charles},
  urldate = {2016-10-31},
  date = {2006},
  pages = {309--318},
  file = {[PDF] aliquote.org:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/4FTRNXN9/Tenenbaum et al. - 2006 - Theory-based Bayesian models of inductive learning.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/ZZITI7QM/consumeSsoCookie.html:text/html}
}

@thesis{saomai2014,
  title = {A {{Curious Robot Learner}} for {{Interactive Goal}}-{{Babbling}}},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.636.1176&rep=rep1&type=pdf},
  timestamp = {2016-12-05T12:54:41Z},
  institution = {{Citeseer}},
  author = {Sao Mai, Nguyen},
  urldate = {2016-12-05},
  date = {2014}
}

@article{noda2014,
  title = {Multimodal Integration Learning of Robot Behavior Using Deep Neural Networks},
  volume = {62},
  issn = {0921-8890},
  url = {http://www.sciencedirect.com/science/article/pii/S0921889014000396},
  doi = {10.1016/j.robot.2014.03.003},
  abstract = {For humans to accurately understand the world around them, multimodal integration is essential because it enhances perceptual precision and reduces ambiguity. Computational models replicating such human ability may contribute to the practical use of robots in daily human living environments; however, primarily because of scalability problems that conventional machine learning algorithms suffer from, sensory-motor information processing in robotic applications has typically been achieved via modal-dependent processes. In this paper, we propose a novel computational framework enabling the integration of sensory-motor time-series data and the self-organization of multimodal fused representations based on a deep learning approach. To evaluate our proposed model, we conducted two behavior-learning experiments utilizing a humanoid robot; the experiments consisted of object manipulation and bell-ringing tasks. From our experimental results, we show that large amounts of sensory-motor information, including raw RGB images, sound spectrums, and joint angles, are directly fused to generate higher-level multimodal representations. Further, we demonstrated that our proposed framework realizes the following three functions: (1) cross-modal memory retrieval utilizing the information complementation capability of the deep autoencoder; (2) noise-robust behavior recognition utilizing the generalization capability of multimodal features; and (3) multimodal causality acquisition and sensory-motor prediction based on the acquired causality.},
  timestamp = {2016-11-10T08:36:34Z},
  number = {6},
  journaltitle = {Robotics and Autonomous Systems},
  author = {Noda, Kuniaki and Arie, Hiroaki and Suga, Yuki and Ogata, Tetsuya},
  urldate = {2016-11-10},
  date = {2014-06},
  pages = {721--736},
  keywords = {Cross-modal memory retrieval,Deep learning,Multimodal integration,Object manipulation}
}

@inproceedings{mohammad2010,
  title = {Learning Interaction Protocols Using {{Augmented Baysian Networks}} Applied to Guided Navigation},
  doi = {10.1109/IROS.2010.5651719},
  abstract = {Research in robot navigation usually concentrates on implementing navigation algorithms that allow the robot to navigate without human aid. In many real world situations, it is desirable that the robot is able to understand natural gestures from its user or partner and use this understanding to guide its navigation. Some algorithms already exist for learning natural gestures and/or their associated actions but most of these systems does not allow the robot to automatically generate the associated controller that allows it to actually navigate in the real environment. Furthermore, a technique is needed to combine the gestures/actions learned from interacting with multiple users or partners. This paper resolves these two issues and provides a complete system that allows the robot to learn interaction protocols and act upon them using only unsupervised learning techniques and enables it to combine the protocols learned from multiple users/partners. The proposed approach is general and can be applied to other interactive tasks as well. This paper also provides a real world experiment involving 18 subjects and 72 sessions that supports the ability of the proposed system to learn the needed gestures and to improve its knowledge of different gestures and their associations to actions over time.},
  eventtitle = {2010 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  timestamp = {2016-12-07T14:45:26Z},
  booktitle = {2010 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Mohammad, Y. and Nishida, T.},
  date = {2010-10},
  pages = {4119--4126},
  keywords = {augmented Bayesian networks,Bayes methods,gesture analysis,gesture recognition,guided navigation,learning interaction protocols,path planning,robot navigation,unsupervised learning,unsupervised learning techniques},
  file = {IEEE Xplore Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/GWQKFQ8J/Mohammad et Nishida - 2010 - Learning interaction protocols using Augmented Bay.pdf:application/pdf;IEEE Xplore Abstract Record:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/G4V4T2KI/5651719.html:text/html}
}

@inproceedings{tassa2008,
  title = {Receding Horizon Differential Dynamic Programming},
  url = {http://papers.nips.cc/paper/3297-receding-horizon-differential-dynamic-programming},
  timestamp = {2016-11-17T10:21:16Z},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Tassa, Yuval and Erez, Tom and Smart, William D.},
  urldate = {2016-11-17},
  date = {2008},
  pages = {1465--1472}
}

@article{mnih2015,
  title = {Human-Level Control through Deep Reinforcement Learning},
  volume = {518},
  rights = {© 2015 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  issn = {0028-0836},
  url = {http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html},
  doi = {10.1038/nature14236},
  abstract = {The theory of reinforcement learning provides a normative account, deeply rooted in psychological and neuroscientific perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms. While reinforcement learning agents have achieved some successes in a variety of domains, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks.},
  timestamp = {2016-10-10T13:54:06Z},
  langid = {english},
  number = {7540},
  journaltitle = {Nature},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  urldate = {2016-10-10},
  date = {2015-02-26},
  pages = {529--533},
  keywords = {deep reinforcement learning},
  file = {Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/9S2CMKQ7/Mnih et al. - 2015 - Human-level control through deep reinforcement lea.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/ACV2HM9A/nature14236.html:text/html}
}

@online{centerforhistoryandnewmedia,
  title = {Guide Rapide Pour Débuter},
  url = {http://zotero.org/support/quick_start_guide},
  timestamp = {2016-12-06T16:00:01Z},
  author = {{Center for History and New Media}}
}

@inproceedings{thomaz2006a,
  title = {Transparency and Socially Guided Machine Learning},
  url = {http://www.cc.gatech.edu/~athomaz/papers/ThomazBreazeal-ICDL06.pdf},
  timestamp = {2016-11-09T17:34:00Z},
  booktitle = {5th {{Intl}}. {{Conf}}. on {{Development}} and {{Learning}} ({{ICDL}})},
  author = {Thomaz, Andrea L. and Breazeal, Cynthia},
  urldate = {2016-11-09},
  date = {2006}
}

@article{stulp2013,
  title = {Robot Skill Learning: {{From}} Reinforcement Learning to Evolution Strategies},
  volume = {4},
  url = {http://www.degruyter.com/view/j/pjbr.2013.4.issue-1/pjbr-2013-0003/pjbr-2013-0003.xml},
  shorttitle = {Robot Skill Learning},
  timestamp = {2016-10-31T14:47:54Z},
  number = {1},
  journaltitle = {Paladyn, Journal of Behavioral Robotics},
  author = {Stulp, Freek and Sigaud, Olivier},
  urldate = {2016-10-31},
  date = {2013},
  pages = {49--61},
  file = {Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/26BJD7M4/pjbr-2013-0003.html:text/html}
}

@inproceedings{grizou2014,
  title = {Interactive {{Learning}} from {{Unlabeled Instructions}}},
  url = {https://hal.archives-ouvertes.fr/hal-01007689/document},
  abstract = {Interactive learning deals with the problem of learning and solving tasks using human instructions. It is common in human-robot interaction, tutoring systems, and in human-computer interfaces such as brain-computer ones. In most cases, learning these tasks is possible because the signals are predefined or an ad-hoc calibration procedure allows to map signals to specific meanings. In this paper, we address the problem of simultaneously solving a task under human feedback and learning the associated meanings of the feedback signals. This has important practical application since the user can start controlling a device from scratch, without the need of an expert to define the meaning of signals or carrying out a calibration phase. The paper proposes an algorithm that simultaneously assign meanings to signals while solving a sequential task under the assumption that both, human and machine, share the same a priori on the possible instruction meanings and the possible tasks. Furthermore, we show using synthetic and real EEG data from a brain-computer interface that taking into account the uncertainty of the task and the signal is necessary for the machine to actively plan how to solve the task efficiently.},
  eventtitle = {UAI-30th Conference on Uncertainty in Artificial Intelligence},
  timestamp = {2016-10-13T13:13:50Z},
  langid = {english},
  author = {Grizou, Jonathan and Iturrate, Iñaki and Montesano, Luis and Oudeyer, Pierre-Yves and Lopes, Manuel},
  urldate = {2016-10-12},
  date = {2014-07-23},
  pages = {1--8},
  keywords = {interactive learning},
  file = {Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/A8KHI74A/Grizou et al. - 2014 - Interactive Learning from Unlabeled Instructions.pdf:application/pdf;Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/CCUP2CDV/Grizou et al. - 2014 - Interactive Learning from Unlabeled Instructions.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/6JIN8SUA/en.html:text/html;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/KSQSFKDI/en.html:text/html}
}

@article{rolf2014a,
  title = {Explorative Learning of Inverse Models: {{A}} Theoretical Perspective},
  volume = {131},
  issn = {0925-2312},
  url = {http://www.sciencedirect.com/science/article/pii/S0925231213010977},
  doi = {10.1016/j.neucom.2013.04.050},
  shorttitle = {Explorative Learning of Inverse Models},
  abstract = {We investigate the role of redundancy for exploratory learning of inverse functions, where an agent learns to achieve goals by performing actions and observing outcomes. We present an analysis of linear redundancy and investigate goal-directed exploration approaches, which are empirically successful, but hardly theorized except negative results for special cases, and prove convergence to the optimal solution. We show that the learning curves of such processes are intrinsically low-dimensional and S-shaped, which explains previous empirical findings, and finally compare our results to non-linear domains.},
  timestamp = {2016-12-05T13:01:37Z},
  journaltitle = {Neurocomputing},
  author = {Rolf, Matthias and Steil, Jochen J.},
  urldate = {2016-12-05},
  date = {2014-05-05},
  pages = {2--14},
  keywords = {Exploration,Goal babbling,Inverse models,Motor learning,Redundancy}
}

@inproceedings{inamura2010,
  title = {Simulator Platform That Enables Social Interaction simulation—{{SIGVerse}}: {{SocioIntelliGenesis}} Simulator},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5708327},
  shorttitle = {Simulator Platform That Enables Social Interaction simulation—{{SIGVerse}}},
  timestamp = {2016-11-18T11:51:49Z},
  booktitle = {System {{Integration}} ({{SII}}), 2010 {{IEEE}}/{{SICE International Symposium}} on},
  publisher = {{IEEE}},
  author = {Inamura, Tetsunari and Shibata, Tomohiro and Sena, Hideaki and Hashimoto, Takashi and Kawai, Nobuyuki and Miyashita, Takahiro and Sakurai, Yoshiki and Shimizu, Masahiro and Otake, Mihoko and Hosoda, Koh and {others}},
  urldate = {2016-11-18},
  date = {2010},
  pages = {212--217}
}

@article{ondruska,
  title = {Neural {{Robotics}}-{{A New Perspective AAAI Robotics Fellowship}} 2016},
  url = {http://www.robots.ox.ac.uk/~mobile/Papers/2016AAAI_RF_ondruska.pdf},
  timestamp = {2016-11-09T22:15:53Z},
  author = {Ondruska, Peter},
  urldate = {2016-11-09}
}

@article{sun2010,
  title = {Learning Visual Object Categories for Robot Affordance Prediction},
  volume = {29},
  url = {http://ijr.sagepub.com/content/29/2-3/174.short},
  timestamp = {2016-11-18T15:42:26Z},
  issue = {2-3},
  journaltitle = {The International Journal of Robotics Research},
  author = {Sun, Jie and Moore, Joshua L. and Bobick, Aaron and Rehg, James M.},
  urldate = {2016-11-18},
  date = {2010},
  pages = {174--197}
}

@inproceedings{lohan2011,
  title = {Contingency Allows the Robot to Spot the Tutor and to Learn from Interaction},
  volume = {2},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6037341},
  timestamp = {2016-11-07T15:35:24Z},
  booktitle = {2011 {{IEEE International Conference}} on {{Development}} and {{Learning}} ({{ICDL}})},
  publisher = {{IEEE}},
  author = {Lohan, Katrin S. and Pitsch, Karola and Rohlfing, Katharina J. and Fischer, Kerstin and Saunders, Joe and Lehmann, Hagen and Nehaniv, Chrystopher and Wrede, Britta},
  urldate = {2016-11-07},
  date = {2011},
  pages = {1--8}
}

@article{grossberg2010,
  title = {How Do Children Learn to Follow Gaze, Share Joint Attention, Imitate Their Teachers, and Use Tools during Social Interactions?},
  volume = {23},
  url = {http://www.sciencedirect.com/science/article/pii/S0893608010001504},
  timestamp = {2016-11-07T17:27:47Z},
  number = {8},
  journaltitle = {Neural Networks},
  author = {Grossberg, Stephen and Vladusich, Tony},
  urldate = {2016-11-07},
  date = {2010},
  pages = {940--965}
}

@article{georgeon2013,
  title = {Demonstrating Sensemaking Emergence in Artificial Agents: {{A}} Method and an Example},
  volume = {5},
  url = {http://www.worldscientific.com/doi/abs/10.1142/S1793843013500029},
  shorttitle = {Demonstrating Sensemaking Emergence in Artificial Agents},
  timestamp = {2016-12-08T16:02:32Z},
  issue = {02},
  journaltitle = {International Journal of Machine Consciousness},
  author = {Georgeon, Olivier L. and Marshall, James B.},
  urldate = {2016-12-08},
  date = {2013},
  pages = {131--144},
  file = {Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/6QIAMP5U/S1793843013500029.html:text/html}
}

@thesis{lin1992,
  location = {{Pittsburgh, PA, USA}},
  title = {Reinforcement {{Learning}} for {{Robots Using Neural Networks}}},
  abstract = {Reinforcement learning agents are adaptive, reactive, and self-supervised. The aim of this dissertation is to extend the state of the art of reinforcement learning and enable its applications to complex robot-learning problems. In particular, it focuses on two issues. First, learning from sparse and delayed reinforcement signals is hard and in general a slow process. Techniques for reducing learning time must be devised. Second, most existing reinforcement learning methods assume that the world is a Markov decision process. This assumption is too strong for many robot tasks of interest.This dissertation demonstrates how we can possibly overcome the slow learning problem and tackle non-Markovian environments, making reinforcement learning more practical for realistic robot tasks: (1) Reinforcement learning can be naturally integrated with artificial neural networks to obtain high-quality generalization, resulting in a significant learning speedup. Neural networks are used in this dissertation, and they generalize effectively even in the presence of noise and a large of binary and real-valued inputs. (2) Reinforcement learning agents can save many learning trials by using an action model, which can be learned on-line. With a model, an agent can mentally experience the effects of its actions without actually executing them. Experience replay is a simple technique that implements this idea, and is shown to be effective in reducing the number of action executions required. (3) Reinforcement learning agents can take advantage of instructive training instances provided by human teachers, resulting in a significant learning speedup. Teaching can also help learning agents avoid local optima during the search for optimal control. Simulation experiments indicate that even a small amount of teaching can save agents many learning trials. (4) Reinforcement learning agents can significantly reduce learning time by hierarchical learning--they first solve elementary learning problems and then combine solutions to the elementary problems to solve a complex problem. Simulation experiments indicate that a robot with hierarchical learning can solve a complex problem, which otherwise is hardly solvable within a reasonable time. (5) Reinforcement learning agents can deal with a wide range of non-Markovian environments by having a memory of their past. Three memory architectures are discussed. They work reasonably well for a variety of simple problems. One of them is also successfully applied to a nontrivial non-Markovian robot task.The results of this dissertation rely on computer simulation, including (1) an agent operating in a dynamic and hostile environment and (2) a mobile robot operating in a noisy and non-Markovian environment. The robot simulator is physically realistic. This dissertation concludes that it is possible to build artificial agents than can acquire complex control policies effectively by reinforcement learning.},
  timestamp = {2016-10-13T15:58:53Z},
  institution = {{Carnegie Mellon University}},
  author = {Lin, Long-Ji},
  date = {1992},
  note = {UMI Order No. GAX93-22750}
}

@inproceedings{watter2015,
  title = {Embed to Control: {{A}} Locally Linear Latent Dynamics Model for Control from Raw Images},
  url = {http://papers.nips.cc/paper/5964-embed-to-control-a-locally-linear-latent-dynamics-model-for-control-from-raw-images},
  shorttitle = {Embed to Control},
  timestamp = {2016-11-17T10:21:33Z},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Watter, Manuel and Springenberg, Jost and Boedecker, Joschka and Riedmiller, Martin},
  urldate = {2016-11-17},
  date = {2015},
  pages = {2746--2754}
}

@article{pezzulo,
  title = {From {{Actions}} to {{Goals}} and {{Vice}}-Versa: {{Theoretical Analysis}} and {{Models}} of the {{Ideomotor Principle}} and {{TOTE}}},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.330.6627&rep=rep1&type=pdf},
  shorttitle = {From {{Actions}} to {{Goals}} and {{Vice}}-Versa},
  timestamp = {2016-10-31T14:41:55Z},
  author = {Pezzulo, Giovanni and Baldassarre, Gianluca and Butz, Martin V. and Castelfranchi, Cristiano and Hoffmann, Joachim},
  urldate = {2016-10-31}
}

@article{amershi2014,
  title = {Power to the {{People}}: {{The Role}} of {{Humans}} in {{Interactive Machine Learning}}},
  url = {https://www.microsoft.com/en-us/research/publication/power-to-the-people-the-role-of-humans-in-interactive-machine-learning/},
  shorttitle = {Power to the {{People}}},
  abstract = {Systems that can learn interactively from their end-users are quickly becoming widespread. Until recently, this progress has been fueled mostly by advances in machine learning; however, more and more researchers are realizing the importance of studying users of these systems. In this article we promote this approach and demonstrate how it can result in better ...},
  timestamp = {2016-10-14T10:30:26Z},
  journaltitle = {AI Magazine},
  author = {Amershi, Saleema and Cakmak, Maya and Knox, W. Bradley and Kulesza, Todd},
  urldate = {2016-10-13},
  date = {2014-12-01},
  file = {Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/JWKHGE3F/Amershi et al. - 2014 - Power to the People The Role of Humans in Interac.pdf:application/pdf;Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/QF4SZM4C/Amershi et al. - 2014 - Power to the People The Role of Humans in Interac.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/4PE73WMR/Amershi et al. - 2014 - Power to the People The Role of Humans in Interac.html:text/html;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/NR6C8XWA/Amershi et al. - 2014 - Power to the People The Role of Humans in Interac.html:text/html}
}

@article{ugur2011,
  title = {Goal Emulation and Planning in Perceptual Space Using Learned Affordances},
  volume = {59},
  url = {http://www.sciencedirect.com/science/article/pii/S0921889011000741},
  timestamp = {2016-11-25T09:20:09Z},
  number = {7},
  journaltitle = {Robotics and Autonomous Systems},
  author = {Ugur, Emre and Oztop, Erhan and Sahin, Erol},
  urldate = {2016-11-25},
  date = {2011},
  pages = {580--595}
}

@article{rolf2010,
  title = {Goal Babbling Permits Direct Learning of Inverse Kinematics},
  volume = {2},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5535131},
  timestamp = {2016-12-02T10:24:47Z},
  number = {3},
  journaltitle = {IEEE Transactions on Autonomous Mental Development},
  author = {Rolf, Matthias and Steil, Jochen J. and Gienger, Michael},
  urldate = {2016-12-02},
  date = {2010},
  pages = {216--229}
}

@inproceedings{koppula2014,
  title = {Physically Grounded Spatio-Temporal Object Affordances},
  url = {http://link.springer.com/chapter/10.1007/978-3-319-10578-9_54},
  timestamp = {2016-12-07T17:44:59Z},
  booktitle = {European {{Conference}} on {{Computer Vision}}},
  publisher = {{Springer}},
  author = {Koppula, Hema S. and Saxena, Ashutosh},
  urldate = {2016-12-07},
  date = {2014},
  pages = {831--847},
  file = {Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/TSBQ5FHG/978-3-319-10578-9_54.html:text/html}
}

@article{pantelis2014,
  title = {Inferring the Intentional States of Autonomous Virtual Agents},
  volume = {130},
  url = {http://www.sciencedirect.com/science/article/pii/S0010027713002291},
  timestamp = {2016-12-13T15:42:28Z},
  number = {3},
  journaltitle = {Cognition},
  author = {Pantelis, Peter C. and Baker, Chris L. and Cholewiak, Steven A. and Sanik, Kevin and Weinstein, Ari and Wu, Chia-Chien and Tenenbaum, Joshua B. and Feldman, Jacob},
  urldate = {2016-12-13},
  date = {2014},
  pages = {360--379}
}

@article{asada2009,
  title = {Cognitive Developmental Robotics: A Survey},
  volume = {1},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4895715},
  shorttitle = {Cognitive Developmental Robotics},
  timestamp = {2016-10-31T14:32:26Z},
  number = {1},
  journaltitle = {IEEE Transactions on Autonomous Mental Development},
  author = {Asada, Minoru and Hosoda, Koh and Kuniyoshi, Yasuo and Ishiguro, Hiroshi and Inui, Toshio and Yoshikawa, Yuichiro and Ogino, Masaki and Yoshida, Chisato},
  urldate = {2016-10-31},
  date = {2009},
  pages = {12--34}
}

@inproceedings{kozima2001,
  title = {A Robot That Learns to Communicate with Human Caregivers},
  url = {http://www.lucs.lu.se/LUCS/085/Kozima.pdf},
  timestamp = {2016-11-09T17:43:27Z},
  booktitle = {Proceedings of the {{First International Workshop}} on {{Epigenetic Robotics}}},
  author = {Kozima, Hideki and Yano, Hiroyuki},
  urldate = {2016-11-09},
  date = {2001},
  pages = {47--52}
}

@inproceedings{ng2000,
  title = {Algorithms for Inverse Reinforcement Learning.},
  url = {http://ai.stanford.edu/~ang/papers/icml00-irl.pdf},
  timestamp = {2016-10-31T14:16:21Z},
  booktitle = {Icml},
  author = {Ng, Andrew Y. and Russell, Stuart J. and {others}},
  urldate = {2016-10-31},
  date = {2000},
  pages = {663--670},
  file = {[PDF] stanford.edu:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/SC5KBWP3/Ng et al. - 2000 - Algorithms for inverse reinforcement learning..pdf:application/pdf}
}

@inproceedings{lan2014,
  title = {A Hierarchical Representation for Future Action Prediction},
  url = {http://link.springer.com/chapter/10.1007/978-3-319-10578-9_45},
  timestamp = {2016-11-17T17:40:19Z},
  booktitle = {European {{Conference}} on {{Computer Vision}}},
  publisher = {{Springer}},
  author = {Lan, Tian and Chen, Tsung-Chuan and Savarese, Silvio},
  urldate = {2016-11-17},
  date = {2014},
  pages = {689--704}
}

@article{rolf2012,
  title = {Goal Babbling: A New Concept for Early Sensorimotor Exploration},
  volume = {11},
  url = {http://corwww.techfak.uni-bielefeld.de/system/files/RolfSteil2012-DevRob-GoalBabbling.pdf},
  shorttitle = {Goal Babbling},
  timestamp = {2016-12-02T09:56:27Z},
  journaltitle = {Osaka},
  author = {Rolf, Matthias and Steil, Jochen J. and {others}},
  urldate = {2016-12-02},
  date = {2012},
  pages = {2012}
}

@inproceedings{grizou2013,
  location = {{Osaka, Japan}},
  title = {Robot {{Learning Simultaneously}} a {{Task}} and {{How}} to {{Interpret Human Instructions}}},
  url = {https://hal.archives-ouvertes.fr/hal-00850703},
  abstract = {This paper presents an algorithm to bootstrap shared understanding in a human-robot interaction scenario where the user teaches a robot a new task using teaching instructions yet unknown to it. In such cases, the robot needs to estimate simultaneously what the task is and the associated meaning of instructions received from the user. For this work, we consider a scenario where a human teacher uses initially unknown spoken words, whose associated unknown meaning is either a feedback (good/bad) or a guidance (go left, right, ...). We present computational results, within an inverse reinforcement learning framework, showing that a) it is possible to learn the meaning of unknown and noisy teaching instructions, as well as a new task at the same time, b) it is possible to reuse the acquired knowledge about instructions for learning new tasks, and c) even if the robot initially knows some of the instructions' meanings, the use of extra unknown teaching instructions improves learning efficiency.},
  timestamp = {2016-10-13T13:13:51Z},
  booktitle = {Joint {{IEEE International Conference}} on {{Development}} and {{Learning}} an on {{Epigenetic Robotics}} ({{ICDL}}-{{EpiRob}})},
  author = {Grizou, Jonathan and Lopes, Manuel and Oudeyer, Pierre-Yves},
  urldate = {2016-10-12},
  date = {2013-08},
  keywords = {interactive learning,learning theory,robot task learning},
  file = {IEEE Xplore Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/MBXC28XJ/Grizou et al. - 2013 - Robot learning simultaneously a task and how to in.pdf:application/pdf;IEEE Xplore Abstract Record:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/EB55GUP3/Grizou et al. - 2013 - Robot learning simultaneously a task and how to in.html:text/html;IEEE Xplore Abstract Record:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/HGK29QSJ/6652523.html:text/html;IEEE Xplore Abstract Record:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/NX3DJVJD/6652523.html:text/html;HAL Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/VUT7R6H4/hal-00850703.html:text/html}
}

@online{zotero-null-106,
  title = {Evolving {{AI Lab}} - {{University}} of {{Wyoming}}},
  url = {http://www.evolvingai.org/yosinski-clune-hidalgo-nguyen-2011-evolving-robot-gaits-hardware},
  abstract = {The Evolving AI Lab at the University of Wyoming focuses on evolving artificially intelligent robots. Please visit EvolvingAI.org to watch videos of, and read about, our work.},
  timestamp = {2016-11-07T17:48:56Z},
  urldate = {2016-11-07}
}

@phdthesis{grizou2014a,
  title = {Learning from {{Unlabeled Interaction Frames}}},
  url = {https://hal.inria.fr/tel-01095562/document},
  abstract = {This thesis investigates how a machine can be taught a new task from unlabeled human instructions, which is without knowing beforehand how to associate the human communicative signals with their meanings. The theoretical and empirical work presented in this thesis provides means to create calibration free interactive systems, which allow humans to interact with machines, from scratch, using their own preferred teaching signals. It therefore removes the need for an expert to tune the system for each specific user, which constitutes an important step towards flexible personalized teaching interfaces, a key for the future of personal robotics.Our approach assumes the robot has access to a limited set of task hypotheses, which include the task the user wants to solve. Our method consists of generating interpretation hypotheses of the teaching signals with respect to each hypothetic task. By building a set of hypothetic interpretation, i.e. a set of signal-label pairs for each task, the task the user wants to solve is the one that explains better the history of interaction.We consider different scenarios, including a pick and place robotics experiment with speech as the modality of interaction, and a navigation task in a brain computer interaction scenario. In these scenarios, a teacher instructs a robot to perform a new task using initially unclassified signals, whose associated meaning can be a feedback (correct/incorrect) or a guidance (go left, right, up, $\backslash$ldots). Our results show that a) it is possible to learn the meaning of unlabeled and noisy teaching signals, as well as a new task at the same time, and b) it is possible to reuse the acquired knowledge about the teaching signals for learning new tasks faster. We further introduce a planning strategy that exploits uncertainty from the task and the signals' meanings to allow more efficient learning sessions. We present a study where several real human subjects control successfully a virtual device using their brain and without relying on a calibration phase. Our system identifies, from scratch, the target intended by the user as well as the decoder of brain signals.Based on this work, but from another perspective, we introduce a new experimental setup to study how humans behave in asymmetric collaborative tasks. In this setup, two humans have to collaborate to solve a task but the channels of communication they can use are constrained and force them to invent and agree on a shared interaction protocol in order to solve the task. These constraints allow analyzing how a communication protocol is progressively established through the interplay and history of individual actions.},
  timestamp = {2016-10-13T13:24:46Z},
  langid = {english},
  institution = {{Université de Bordeaux}},
  author = {Grizou, Jonathan},
  urldate = {2016-10-13},
  date = {2014-10-24},
  keywords = {interactive learning,pragmatic frames},
  file = {Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/7J9GKIF2/Grizou - 2014 - Learning from Unlabeled Interaction Frames.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/JV9BHGAE/tel-01095562v1.html:text/html}
}

@article{korattikara2015,
  title = {Bayesian Dark Knowledge},
  url = {http://arxiv.org/abs/1506.04416},
  timestamp = {2016-11-17T11:43:51Z},
  journaltitle = {arXiv preprint arXiv:1506.04416},
  author = {Korattikara, Anoop and Rathod, Vivek and Murphy, Kevin and Welling, Max},
  urldate = {2016-11-17},
  date = {2015}
}

@article{woodward2012,
  title = {Framing {{Human}}-{{Robot Task Communication}} as a {{POMDP}}},
  url = {http://arxiv.org/abs/1204.0280},
  timestamp = {2016-12-21T15:18:31Z},
  journaltitle = {arXiv preprint arXiv:1204.0280},
  author = {Woodward, Mark P. and Wood, Robert J.},
  urldate = {2016-12-21},
  date = {2012}
}

@article{kose-bagci2010,
  title = {Drum-Mate: Interaction Dynamics and Gestures in Human–humanoid Drumming Experiments},
  volume = {22},
  url = {http://www.tandfonline.com/doi/abs/10.1080/09540090903383189},
  shorttitle = {Drum-Mate},
  timestamp = {2016-11-09T17:49:14Z},
  number = {2},
  journaltitle = {Connection Science},
  author = {Kose-Bagci, Hatice and Dautenhahn, Kerstin and Syrdal, Dag S. and Nehaniv, Chrystopher L.},
  urldate = {2016-11-09},
  date = {2010},
  pages = {103--134}
}

@inproceedings{najar2015a,
  title = {Social-{{Task Learning}} for {{HRI}}},
  url = {http://link.springer.com/chapter/10.1007/978-3-319-25554-5_47},
  timestamp = {2016-11-02T10:50:03Z},
  booktitle = {International {{Conference}} on {{Social Robotics}}},
  publisher = {{Springer}},
  author = {Najar, Anis and Sigaud, Olivier and Chetouani, Mohamed},
  urldate = {2016-11-02},
  date = {2015},
  pages = {472--481}
}

@article{cruz,
  title = {Contextual {{Affordances}} for {{Action}}-{{Effect Prediction}} in a {{Robotic}}-{{Cleaning Task}}},
  url = {http://www.academia.edu/download/45307348/Cruz_affordances_IROS2015.pdf},
  timestamp = {2016-12-02T15:56:34Z},
  author = {Cruz, Francisco and Parisi, German I. and Wermter, Stefan},
  urldate = {2016-12-02}
}

@article{stolk2016,
  title = {Conceptual {{Alignment}}: {{How Brains Achieve Mutual Understanding}}},
  volume = {20},
  issn = {1364-6613},
  url = {http://www.sciencedirect.com/science/article/pii/S1364661315002867},
  doi = {10.1016/j.tics.2015.11.007},
  shorttitle = {Conceptual {{Alignment}}},
  abstract = {We share our thoughts with other minds, but we do not understand how. Having a common language certainly helps, but infants’ and tourists’ communicative success clearly illustrates that sharing thoughts does not require signals with a pre-assigned meaning. In fact, human communicators jointly build a fleeting conceptual space in which signals are a means to seek and provide evidence for mutual understanding. Recent work has started to capture the neural mechanisms supporting those fleeting conceptual alignments. The evidence suggests that communicators and addressees achieve mutual understanding by using the same computational procedures, implemented in the same neuronal substrate, and operating over temporal scales independent from the signals’ occurrences.},
  timestamp = {2016-11-07T15:21:24Z},
  number = {3},
  journaltitle = {Trends in Cognitive Sciences},
  author = {Stolk, Arjen and Verhagen, Lennart and Toni, Ivan},
  urldate = {2016-11-07},
  date = {2016-03},
  pages = {180--191}
}

@inproceedings{moldovan2013,
  title = {On the Use of Probabilistic Relational Affordance Models for Sequential Manipulation Tasks in Robotics},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6630737},
  timestamp = {2016-11-23T10:22:41Z},
  booktitle = {Robotics and {{Automation}} ({{ICRA}}), 2013 {{IEEE International Conference}} on},
  publisher = {{IEEE}},
  author = {Moldovan, Bogdan and Moreno, Plinio and van Otterlo, Martijn},
  urldate = {2016-11-23},
  date = {2013},
  pages = {1290--1295},
  options = {useprefix=true}
}

@article{lake2016,
  title = {Building {{Machines That Learn}} and {{Think Like People}}},
  url = {http://arxiv.org/abs/1604.00289},
  abstract = {Recent progress in artificial intelligence (AI) has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn, and how they learn it. Specifically, we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes towards these goals that can combine the strengths of recent neural network advances with more structured cognitive models.},
  timestamp = {2016-10-13T13:18:25Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1604.00289},
  primaryClass = {cs, stat},
  author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
  urldate = {2016-10-13},
  date = {2016-04-01},
  keywords = {developmental robotics},
  file = {arXiv\:1604.00289 PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/HQMISBW8/Lake et al. - 2016 - Building Machines That Learn and Think Like People.pdf:application/pdf;arXiv.org Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/CNHXB6TA/1604.html:text/html}
}

@incollection{zhang2016,
  title = {Learning from {{Few Samples}} with {{Memory Network}}},
  rights = {©2016 Springer International Publishing AG},
  isbn = {978-3-319-46686-6 978-3-319-46687-3},
  url = {http://link.springer.com/chapter/10.1007/978-3-319-46687-3_67},
  abstract = {Neural Networks (NN) have achieved great success in pattern recognition and machine learning. However, the success of NNs usually relies on a sufficiently large number of samples. When fed with limited data, NN’s performance may be degraded significantly. In this paper, we introduce a novel neural network called Memory Network, which can learn better from limited data. Taking advantages of the memory from previous samples, the new model could achieve remarkable performance improvement on limited data. We demonstrate the memory network in Multi-Layer Perceptron (MLP). However, it keeps straightforward to extend our idea to other neural networks, e.g., Convolutional Neural Networks (CNN). We detail the network structure, present the training algorithm, and conduct a series of experiments to validate the proposed framework. Experimental results show that our model outperforms the traditional MLP and other competitive algorithms in two real data sets.},
  timestamp = {2016-11-17T11:14:36Z},
  langid = {english},
  number = {9947},
  booktitle = {Neural {{Information Processing}}},
  series = {Lecture Notes in Computer Science},
  publisher = {{Springer International Publishing}},
  author = {Zhang, Shufei and Huang, Kaizhu},
  editor = {Hirose, Akira and Ozawa, Seiichi and Doya, Kenji and Ikeda, Kazushi and Lee, Minho and Liu, Derong},
  urldate = {2016-11-17},
  date = {2016-10-16},
  pages = {606--614},
  keywords = {Artificial Intelligence (incl. Robotics),Computation by Abstract Devices,Data Mining and Knowledge Discovery,Image Processing and Computer Vision,Memory,Multi-layer perceptron,Pattern Recognition},
  doi = {10.1007/978-3-319-46687-3_67}
}

@inproceedings{calinon2008,
  title = {A Framework Integrating Statistical and Social Cues to Teach a Humanoid Robot New Skills},
  url = {http://infoscience.epfl.ch/record/117850},
  timestamp = {2016-10-31T13:18:43Z},
  booktitle = {Proceedings of the {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}}), {{Workshop}} on {{Social Interaction}} with {{Intelligent Indoor Robots}}},
  author = {Calinon, Sylvain and Billard, Aude},
  urldate = {2016-10-31},
  date = {2008},
  file = {[PDF] epfl.ch:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/UNST27DA/Calinon et Billard - 2008 - A framework integrating statistical and social cue.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/WPIBJ7AI/117850.html:text/html}
}

@inproceedings{wrede2012,
  location = {{Osaka, Japan}},
  title = {Towards Robots with Teleological Action and Language Understanding},
  url = {https://hal.inria.fr/hal-00788627},
  abstract = {It is generally agreed upon that in order to achieve generalizable learning capabilities of robots they need to be able to acquire compositional structures - whether in language or in action. However, in human development the capability to perceive compositional structure only evolves at a later stage. Before the capability to understand action and language in a structured, compositional way arises, infants learn in a holistic way which enables them to interact in a socially adequate way with their social and physical environment even with very limited understanding of the world, e.g. trying to take part in games without knowing the exact rules. This capability endows them with an action production advantage which elicits corrective feedback from a tutor, thus reducing the search space of possible action interpretations tremendously. In accordance with findings from developmental psychology we argue that this holistic way is in fact a teleological representation encoding a goal-directed per- ception of actions facilitated through communicational frames. This observation leads to a range of consequences which need to be verfied and analysed in further research. Here, we discuss two hypotheses how this can be made accessible for action learning in robots: (1) We explore the idea that the teleological approach allows some kind of highly reduced one shot learning enabling the learner to perform a meaningful, although only partially "correct" action which can then be further refined through compositional approaches. (2) We discuss the possibility to transfer the concept of "conversational frames" as recurring interaction patterns to the action domain, thus facilitating to understand the meaning of a new action. We conclude that these capabilities need to be combined with more analytical compositional learning methods in order to achieve human-like learning performance.},
  timestamp = {2016-10-20T12:21:38Z},
  booktitle = {Humanoids 2012 {{Workshop}} on {{Developmental Robotics}}: {{Can}} Developmental Robotics Yield Human-like Cognitive Abilities?},
  author = {Wrede, Britta and Rohlfing, Katharina and Steil, Jochen and Wrede, Sebastian and Oudeyer, Pierre-Yves and Tani, Jun},
  editor = {Ugur, Emre and Nagai, Yukie and Oztop, Erhan and Asada, Minoru},
  urldate = {2016-10-20},
  date = {2012-11},
  file = {Wredeetal12.pdf:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/BV6GRADA/Wredeetal12.pdf:application/pdf;HAL Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/HAZWG4T5/hal-00788627.html:text/html}
}

@article{najar,
  title = {Training a Robot with Evaluative Feedback and Unlabeled Guidance Signals},
  url = {http://www.isir.upmc.fr/files/2016ACTI3709.pdf},
  timestamp = {2016-11-02T10:51:20Z},
  author = {Najar, Anis and Sigaud, Olivier and Chetouani, Mohamed},
  urldate = {2016-11-02}
}

@article{wong2016,
  title = {Towards {{Lifelong Self}}-{{Supervision}}: {{A Deep Learning Direction}} for {{Robotics}}},
  url = {https://arxiv.org/abs/1611.00201},
  shorttitle = {Towards {{Lifelong Self}}-{{Supervision}}},
  timestamp = {2016-11-07T15:05:02Z},
  journaltitle = {arXiv preprint arXiv:1611.00201},
  author = {Wong, Jay M.},
  urldate = {2016-11-07},
  date = {2016}
}

@inproceedings{subramanian2016,
  title = {Exploration from {{Demonstration}} for {{Interactive Reinforcement Learning}}},
  url = {http://dl.acm.org/citation.cfm?id=2936990},
  timestamp = {2016-12-07T16:16:03Z},
  booktitle = {Proceedings of the 2016 {{International Conference}} on {{Autonomous Agents}} \& {{Multiagent Systems}}},
  publisher = {{International Foundation for Autonomous Agents and Multiagent Systems}},
  author = {Subramanian, Kaushik and Isbell Jr, Charles L. and Thomaz, Andrea L.},
  urldate = {2016-12-07},
  date = {2016},
  pages = {447--456},
  file = {Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/ZBKF87J7/citation.html:text/html}
}

@inproceedings{levine2014,
  title = {Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics},
  url = {http://papers.nips.cc/paper/5444-learning-neural-network-policies-with-guided-policy-search-under-unknown-dynamics},
  timestamp = {2016-10-31T14:50:35Z},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Levine, Sergey and Abbeel, Pieter},
  urldate = {2016-10-31},
  date = {2014},
  pages = {1071--1079}
}

@article{andry2011,
  title = {Using the Rhythm of Nonverbal Human–robot Interaction as a Signal for Learning},
  volume = {3},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5664771},
  timestamp = {2016-11-07T15:24:30Z},
  number = {1},
  journaltitle = {IEEE Transactions on Autonomous Mental Development},
  author = {Andry, Pierre and Blanchard, Arnaud and Gaussier, Philippe},
  urldate = {2016-11-07},
  date = {2011},
  pages = {30--42}
}

@article{oudeyer2013,
  title = {Object Learning through Active Exploration},
  url = {http://ieeexplore.ieee.org/iel7/4563672/4815436/06672014.pdf},
  timestamp = {2016-11-12T17:58:01Z},
  author = {Oudeyer, Olivier Sigaud},
  urldate = {2016-11-12},
  date = {2013},
  keywords = {_tablet}
}

@article{yamada2016,
  title = {Dynamical {{Integration}} of {{Language}} and {{Behavior}} in a {{Recurrent Neural Network}} for {{Human}}–{{Robot Interaction}}},
  volume = {10},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4946379/},
  timestamp = {2016-11-07T15:04:40Z},
  journaltitle = {Frontiers in Neurorobotics},
  author = {Yamada, Tatsuro and Murata, Shingo and Arie, Hiroaki and Ogata, Tetsuya},
  urldate = {2016-11-07},
  date = {2016}
}

@inproceedings{chernova2007,
  title = {Confidence-Based Policy Learning from Demonstration Using Gaussian Mixture Models},
  url = {http://dl.acm.org/citation.cfm?id=1329407},
  timestamp = {2016-10-31T13:15:26Z},
  booktitle = {Proceedings of the 6th International Joint Conference on {{Autonomous}} Agents and Multiagent Systems},
  publisher = {{ACM}},
  author = {Chernova, Sonia and Veloso, Manuela},
  urldate = {2016-10-31},
  date = {2007},
  pages = {233},
  file = {[PDF] cmu.edu:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/5ZHWFSX9/Chernova et Veloso - 2007 - Confidence-based policy learning from demonstratio.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/WBMP6WEF/citation.html:text/html}
}

@article{palm2012,
  title = {Prediction as a Candidate for Learning Deep Hierarchical Models of Data},
  volume = {5},
  url = {http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/6284/pdf/imm6284.pdf},
  timestamp = {2016-11-14T23:06:33Z},
  journaltitle = {Technical University of Denmark},
  author = {Palm, Rasmus Berg},
  urldate = {2016-11-14},
  date = {2012}
}

@inproceedings{georgeon2012,
  title = {Interactional Motivation in Artificial Systems: {{Between}} Extrinsic and Intrinsic Motivation},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6400833},
  shorttitle = {Interactional Motivation in Artificial Systems},
  timestamp = {2016-12-08T16:02:14Z},
  booktitle = {2012 {{IEEE International Conference}} on {{Development}} and {{Learning}} and {{Epigenetic Robotics}} ({{ICDL}})},
  publisher = {{IEEE}},
  author = {Georgeon, Olivier L. and Marshall, James B. and Gay, Simon},
  urldate = {2016-12-08},
  date = {2012},
  pages = {1--2},
  file = {Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/MTEIXX8V/6400833.html:text/html}
}

@inproceedings{mirza2008,
  title = {Anticipating Future Experience Using Grounded Sensorimotor Informational Relationships},
  url = {http://uhra.herts.ac.uk/handle/2299/2553},
  timestamp = {2016-11-09T17:52:40Z},
  booktitle = {In: {{Artificial Life XI}}: {{Proceedings}} of the {{Eleventh International Conference}} on the {{Simulation}} and {{Synthesis}} of {{Living Systems}}},
  publisher = {{MIT Press}},
  author = {Mirza, Naeem Assif and Nehaniv, Chrystopher L. and Dautenhahn, Kerstin and Te Boekhorst, René},
  urldate = {2016-11-09},
  date = {2008}
}

@inproceedings{park2010,
  title = {Understanding a Child's Play for Robot Interaction by Sequencing Play Primitives Using Hidden Markov Models},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5509156},
  timestamp = {2016-11-07T16:54:03Z},
  booktitle = {Robotics and {{Automation}} ({{ICRA}}), 2010 {{IEEE International Conference}} on},
  publisher = {{IEEE}},
  author = {Park, Hae Won and Howard, Ayanna M.},
  urldate = {2016-11-07},
  date = {2010},
  pages = {170--177}
}

@inproceedings{todorov2005,
  title = {A Generalized Iterative {{LQG}} Method for Locally-Optimal Feedback Control of Constrained Nonlinear Stochastic Systems},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1469949},
  timestamp = {2016-11-17T10:20:59Z},
  booktitle = {Proceedings of the 2005, {{American Control Conference}}, 2005.},
  publisher = {{IEEE}},
  author = {Todorov, Emanuel and Li, Weiwei},
  urldate = {2016-11-17},
  date = {2005},
  pages = {300--306}
}

@book{droniou2015,
  title = {Apprentissage de Représentations et Robotique Développementale : Quelques Apports de L'apprentissage Profond Pour La Robotique Autonome},
  url = {http://www.theses.fr/2015PA066056},
  shorttitle = {Apprentissage de Représentations et Robotique Développementale},
  abstract = {Afin de pouvoir évoluer de manière autonome et sûre dans leur environnement, les robots doivent être capables d'en construire un modèle fiable et pertinent. Pour des tâches variées dans des environnements complexes, il est difficile de prévoir de manière exhaustive les capacités nécessaires au robot. Il est alors intéressant de doter les robots de mécanismes d'apprentissage leur donnant la possibilité de construire eux-mêmes des représentations adaptées à leur environnement. Se posent alors deux questions : quelle doit être la nature des représentations utilisées et par quels mécanismes peuvent-elles être apprises ? Nous proposons pour cela l'utilisation de l'hypothèse des sous-variétés afin de développer des architectures permettant de faire émerger une représentation symbolique de flux sensorimoteurs bruts. Nous montrons que le paradigme de l'apprentissage profond fournit des mécanismes appropriés à l'apprentissage autonome de telles représentations. Nous démontrons que l'exploitation de la nature multimodale des flux sensorimoteurs permet d'en obtenir une représentation symbolique pertinente. Dans un second temps, nous étudions le problème de l'évolution temporelle des stimuli. Nous discutons les défauts de la plupart des approches aujourd'hui utilisées et nous esquissons une approche à partir de laquelle nous approfondissons deux sous-problèmes. Dans une troisième partie, nous proposons des pistes de recherche pour permettre le passage des expériences de laboratoire à des environnements naturels. Nous explorons plus particulièrement la problématique de la curiosité artificielle dans des réseaux de neurones non supervisés.},
  timestamp = {2016-10-10T13:54:13Z},
  publisher = {{Paris 6}},
  author = {Droniou, Alain},
  urldate = {2016-10-10},
  date = {2015-03-09},
  keywords = {deep learning,developmental robotics,symbol grounding problem},
  file = {Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/J5ABBDS3/Droniou - 2015 - Apprentissage de représentations et robotique déve.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/M6MEGAT9/2015PA066056.html:text/html}
}

@inproceedings{antunes2016,
  title = {From Human Instructions to Robot Actions: {{Formulation}} of Goals, Affordances and Probabilistic Planning},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7487757},
  shorttitle = {From Human Instructions to Robot Actions},
  timestamp = {2016-11-23T10:22:05Z},
  booktitle = {2016 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  publisher = {{IEEE}},
  author = {Antunes, Alexandre and Jamone, Lorenzo and Saponaro, Giovanni and Bernardino, Alexandre and Ventura, Rodrigo},
  urldate = {2016-11-23},
  date = {2016},
  pages = {5449--5454}
}

@article{fern2014,
  title = {A Decision-Theoretic Model of Assistance},
  volume = {50},
  url = {http://dl.acm.org/citation.cfm?id=2693071},
  timestamp = {2016-12-20T16:18:43Z},
  number = {1},
  journaltitle = {Journal of Artificial Intelligence Research},
  author = {Fern, Alan and Natarajan, Sriraam and Judah, Kshitij and Tadepalli, Prasad},
  urldate = {2016-12-20},
  date = {2014},
  pages = {71--104}
}

@inproceedings{abbeel2004a,
  location = {{New York, NY, USA}},
  title = {Apprenticeship {{Learning}} via {{Inverse Reinforcement Learning}}},
  isbn = {978-1-58113-838-2},
  url = {http://doi.acm.org/10.1145/1015330.1015430},
  doi = {10.1145/1015330.1015430},
  abstract = {We consider learning in a Markov decision process where we are not explicitly given a reward function, but where instead we can observe an expert demonstrating the task that we want to learn to perform. This setting is useful in applications (such as the task of driving) where it may be difficult to write down an explicit reward function specifying exactly how different desiderata should be traded off. We think of the expert as trying to maximize a reward function that is expressible as a linear combination of known features, and give an algorithm for learning the task demonstrated by the expert. Our algorithm is based on using "inverse reinforcement learning" to try to recover the unknown reward function. We show that our algorithm terminates in a small number of iterations, and that even though we may never recover the expert's reward function, the policy output by the algorithm will attain performance close to that of the expert, where here performance is measured with respect to the expert's unknown reward function.},
  timestamp = {2017-01-10T14:28:26Z},
  booktitle = {Proceedings of the {{Twenty}}-First {{International Conference}} on {{Machine Learning}}},
  series = {ICML '04},
  publisher = {{ACM}},
  author = {Abbeel, Pieter and Ng, Andrew Y.},
  urldate = {2017-01-10},
  date = {2004},
  pages = {1--}
}

@article{hasnain2012a,
  title = {A Synchrony-Based Perspective for Partner Selection and Attentional Mechanism in Human-Robot Interaction},
  volume = {3},
  url = {http://www.degruyter.com/view/j/pjbr.2012.3.issue-3/s13230-013-0111-y/s13230-013-0111-y.xml},
  timestamp = {2016-11-07T15:36:26Z},
  number = {3},
  journaltitle = {Paladyn, Journal of Behavioral Robotics},
  author = {Hasnain, Syed Khursheed and Mostafaoui, Ghiles and Gaussier, Philippe},
  urldate = {2016-11-07},
  date = {2012},
  pages = {156--171}
}

@inproceedings{hiolle2010,
  title = {Using the Interaction Rhythm as a Natural Reinforcement Signal for Social Robots: A Matter of Belief},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-17248-9_9},
  shorttitle = {Using the Interaction Rhythm as a Natural Reinforcement Signal for Social Robots},
  timestamp = {2016-11-07T16:29:04Z},
  booktitle = {International {{Conference}} on {{Social Robotics}}},
  publisher = {{Springer}},
  author = {Hiolle, Antoine and Cañamero, Lola and Andry, Pierre and Blanchard, Arnaud and Gaussier, Philippe},
  urldate = {2016-11-07},
  date = {2010},
  pages = {81--89}
}

@article{mitchell1993,
  title = {Explanation-Based Neural Network Learning for Robot Control},
  url = {https://pdfs.semanticscholar.org/9489/501aaf1eb5fdd757c879e95f990aa9cc0a7c.pdf},
  timestamp = {2016-10-31T10:24:24Z},
  journaltitle = {Advances in neural information processing systems},
  author = {Mitchell, Tom M. and Thrun, Sebastian B. and {others}},
  urldate = {2016-10-31},
  date = {1993},
  pages = {287--287},
  file = {[PDF] semanticscholar.org:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/BWSM3S6C/Mitchell et al. - 1993 - Explanation-based neural network learning for robo.pdf:application/pdf}
}

@article{starzyk2016,
  title = {Needs, {{Pains}}, and {{Motivations}} in {{Autonomous Agents}}},
  url = {http://ncn.wsiz.rzeszow.pl/wp-content/uploads/2013/10/Needs-Pains-Motivations-Revised.pdf},
  timestamp = {2016-11-23T17:43:27Z},
  journaltitle = {IEEE Trans. Neural Networks Learn. Syst},
  author = {Starzyk, Janusz A. and Graham, James and Puzio, Leszek},
  urldate = {2016-11-23},
  date = {2016}
}

@article{kiela2016,
  title = {Virtual {{Embodiment}}: {{A Scalable Long}}-{{Term Strategy}} for {{Artificial Intelligence Research}}},
  url = {https://arxiv.org/abs/1610.07432},
  shorttitle = {Virtual {{Embodiment}}},
  timestamp = {2016-11-16T09:50:38Z},
  journaltitle = {arXiv preprint arXiv:1610.07432},
  author = {Kiela, Douwe and Bulat, Luana and Vero, Anita L. and Clark, Stephen},
  urldate = {2016-11-16},
  date = {2016}
}

@article{taniguchi2015,
  title = {Symbol {{Emergence}} in {{Robotics}}: {{A Survey}}},
  url = {http://arxiv.org/abs/1509.08973},
  shorttitle = {Symbol {{Emergence}} in {{Robotics}}},
  timestamp = {2016-11-17T14:39:43Z},
  journaltitle = {arXiv preprint arXiv:1509.08973},
  author = {Taniguchi, Tadahiro and Nagai, Takayuki and Nakamura, Tomoaki and Iwahashi, Naoto and Ogata, Tetsuya and Asoh, Hideki},
  urldate = {2016-11-17},
  date = {2015}
}

@article{trafton2005,
  title = {Enabling Effective Human-Robot Interaction Using Perspective-Taking in Robots},
  volume = {35},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1453694},
  timestamp = {2016-10-31T10:31:10Z},
  number = {4},
  journaltitle = {IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans},
  author = {Trafton, J. Gregory and Cassimatis, Nicholas L. and Bugajska, Magdalena D. and Brock, Derek P. and Mintz, Farilee E. and Schultz, Alan C.},
  urldate = {2016-10-31},
  date = {2005},
  pages = {460--470},
  file = {[PDF] dtic.mil:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/9VAJT2XV/Trafton et al. - 2005 - Enabling effective human-robot interaction using p.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/W8JMJFUN/1453694.html:text/html}
}

@article{baker2014,
  title = {Modeling Human Plan Recognition Using Bayesian Theory of Mind},
  url = {http://www.hpctoday.com/files/docs/pdfs/plan_activity_and_intent_recognition.pdf},
  timestamp = {2016-12-13T15:32:44Z},
  journaltitle = {Plan, activity, and intent recognition: Theory and practice},
  author = {Baker, Chris L. and Tenenbaum, Joshua B.},
  urldate = {2016-12-13},
  date = {2014},
  pages = {177--204}
}

@article{lang2010,
  title = {Planning with Noisy Probabilistic Relational Rules},
  volume = {39},
  url = {http://www.aaai.org/Papers/JAIR/Vol39/JAIR-3901.pdf},
  timestamp = {2016-12-02T17:29:00Z},
  number = {1},
  journaltitle = {Journal of Artificial Intelligence Research},
  author = {Lang, Tobias and Toussaint, Marc},
  urldate = {2016-12-02},
  date = {2010},
  pages = {1--49}
}

@inproceedings{hasselt2010,
  title = {Double {{Q}}-Learning},
  url = {http://papers.nips.cc/paper/3964-double-q-learning},
  timestamp = {2016-11-02T13:30:02Z},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Hasselt, Hado V.},
  urldate = {2016-11-02},
  date = {2010},
  pages = {2613--2621}
}

@article{wulfmeier2015,
  title = {Maximum {{Entropy Deep Inverse Reinforcement Learning}}},
  url = {https://pdfs.semanticscholar.org/270a/f733bcf18d9c14230bcffc77d6ae57e2667d.pdf},
  timestamp = {2016-11-07T15:00:36Z},
  journaltitle = {arXiv preprint arXiv:1507.04888},
  author = {Wulfmeier, Markus and Ondruska, Peter and Posner, Ingmar},
  urldate = {2016-11-07},
  date = {2015}
}

@inproceedings{tadepalli2004,
  title = {Relational Reinforcement Learning: {{An}} Overview},
  url = {https://lirias.kuleuven.be/handle/123456789/131145},
  shorttitle = {Relational Reinforcement Learning},
  timestamp = {2016-11-24T13:00:00Z},
  booktitle = {Proceedings of the {{ICML}}-2004 {{Workshop}} on {{Relational Reinforcement Learning}}},
  author = {Tadepalli, Prasad and Givan, Robert and Driessens, Kurt},
  urldate = {2016-11-24},
  date = {2004},
  pages = {1--9}
}

@article{ho2016,
  title = {Generative Adversarial Imitation Learning},
  url = {https://arxiv.org/abs/1606.03476},
  timestamp = {2016-11-07T15:00:16Z},
  journaltitle = {arXiv preprint arXiv:1606.03476},
  author = {Ho, Jonathan and Ermon, Stefano},
  urldate = {2016-11-07},
  date = {2016}
}

@book{teachers,
  title = {Experiments in {{Socially Guided Exploration}}: {{Lessons Learned}} in {{Building Robots}} That {{Learn}} with and without {{Human Teachers}}},
  shorttitle = {Experiments in {{Socially Guided Exploration}}},
  abstract = {We present a learning system, Socially Guided Exploration, in which a social robot learns new tasks through a combination of self-exploration and interpersonal interaction. The system’s motivational drives (novelty, mastery), along with social scaffolding from a human partner, bias behavior to create learning opportunities for a Reinforcement Learning mechanism. The robot is able to learn on its own, but can flexibly use the guidance of a human teacher to improve performance. We report the results of a series of experiments where the robot learns on its own in addition to being taught by human subjects. We analyze these interactions to understand human teaching behavior and the social dynamics of the human-teacher/robot-learner system. With respect to learning performance, human guidance results in a task set that is significantly more focused and efficient, while self-exploration results in a broader set. Analysis of human teaching behavior reveals insights of social coupling between human teacher and robot learner, different teaching styles, strong consistency in the kinds and frequency of scaffolding acts across teachers, and nuance in the communicative intent behind positive and negative feedback.},
  timestamp = {2016-10-20T11:53:15Z},
  author = {Teachers, Without Human and Thomaz, Andrea L. and B, A. Cynthia Breazeal},
  file = {Citeseer - Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/FAJB94MC/Teachers et al. - Experiments in Socially Guided Exploration Lesson.pdf:application/pdf;Citeseer - Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/DTMQFC66/summary.html:text/html}
}

@article{tagniguchi2015a,
  title = {Multimodal {{Hierarchical Dirichlet Process}}-Based {{Active Perception}}},
  url = {https://pdfs.semanticscholar.org/3298/0a97cdab6d019299d055a685c0ffe24dd4d9.pdf},
  timestamp = {2016-11-13T16:51:31Z},
  journaltitle = {arXiv preprint arXiv:1510.00331},
  author = {Tagniguchi, T. and Takano, Toshiaki and Yoshino, Ryo},
  urldate = {2016-11-13},
  date = {2015}
}

@article{diaconescu2014,
  title = {Inferring on the {{Intentions}} of {{Others}} by {{Hierarchical Bayesian Learning}}},
  volume = {10},
  issn = {1553-7358},
  url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003810},
  doi = {10.1371/journal.pcbi.1003810},
  abstract = {Author Summary The ability to decode another person's intentions is a critical component of social interactions. This is particularly important when we have to make decisions based on someone else's advice. Our research proposes that this complex cognitive skill (social learning) can be translated into a mathematical model, which prescribes a mechanism for mentally simulating another person's intentions. This study demonstrates that this process can be parsimoniously described as the deployment of hierarchical learning. In other words, participants learn about two quantities: the intentions of the person they interact with and the veracity of the recommendations they offer. As participants become more and more confident about their representation of the other's intentions, they make decisions more in accordance with the advice they receive. Importantly, our modeling framework captures individual differences in the social learning process: The estimated “learning fingerprint” can predict other aspects of participants' behavior, such as their perspective-taking abilities and their explicit ratings of the adviser's level of trustworthiness. The present modeling approach can be further applied in the context of psychiatry to identify maladaptive learning processes in disorders where social learning processes are particularly impaired, such as schizophrenia.},
  timestamp = {2016-12-13T15:00:54Z},
  number = {9},
  journaltitle = {PLOS Computational Biology},
  author = {Diaconescu, Andreea O. and Mathys, Christoph and Weber, Lilian A. E. and Daunizeau, Jean and Kasper, Lars and Lomakina, Ekaterina I. and Fehr, Ernst and Stephan, Klaas E.},
  urldate = {2016-12-13},
  date = {2014-09-04},
  pages = {e1003810}
}

@article{marblestone2016,
  title = {Toward an {{Integration}} of {{Deep Learning}} and {{Neuroscience}}},
  url = {http://journal.frontiersin.org/article/10.3389/fncom.2016.00094/full},
  doi = {10.3389/fncom.2016.00094},
  abstract = {Neuroscience has focused on the detailed implementation of computation, studying neural codes, dynamics and circuits. In machine learning, however, artificial neural networks tend to eschew precisely designed codes, dynamics or circuits in favor of brute force optimization of a cost function, often using simple and relatively uniform initial architectures. Two recent developments have emerged within machine learning that create an opportunity to connect these seemingly divergent perspectives. First, structured architectures are used, including dedicated systems for attention, recursion and various forms of short- and long-term memory storage. Second, cost functions and training procedures have become more complex and are varied across layers and over time. Here we think about the brain in terms of these ideas. We hypothesize that (1) the brain optimizes cost functions, (2) the cost functions are diverse and differ across brain locations and over development, and (3) optimization operates within a pre-structured architecture matched to the computational problems posed by behavior. In support of these hypotheses, we argue that a range of implementations of credit assignment through multiple layers of neurons are compatible with our current knowledge of neural circuitry, and that the brain's specialized systems can be interpreted as enabling efficient optimization for specific problem classes. Such a heterogeneously optimized system, enabled by a series of interacting cost functions, serves to make learning data-efficient and precisely targeted to the needs of the organism. We suggest directions by which neuroscience could seek to refine and test these hypotheses.},
  timestamp = {2016-11-07T17:34:46Z},
  journaltitle = {Front. Comput. Neurosci},
  author = {Marblestone, Adam H. and Wayne, Greg and Kording, Konrad P.},
  urldate = {2016-11-07},
  date = {2016},
  pages = {94},
  keywords = {cognitive architecture,cost functions,Neural networks,neuroscience}
}

@book{thomaz,
  title = {Teachable {{Robots}}: {{Understanding Human Teaching Behavior}} to {{Build More Effective Robot Learners}}},
  shorttitle = {Teachable {{Robots}}},
  abstract = {While Reinforcement Learning (RL) is not traditionally designed for interactive supervisory input from a human teacher, several works in both robot and software agents have adapted it for human input by letting a human trainer control the reward signal. In this work, we experimentally examine the assumption underlying these works, namely that the human-given reward is compatible with the traditional RL reward signal. We describe an experimental platform with a simulated RL robot and present an analysis of real-time human teaching behavior found in a study in which untrained subjects taught the robot to perform a new task. We report three main observations on how people administer feedback when teaching a robot a task through Reinforcement Learning: (a) they use the reward channel not only for feedback, but also for future-directed guidance; (b) they have a positive bias to their feedback — possibly using the signal as a motivational channel; and (c) they change their behavior as they develop a mental model of the robotic learner. Given this, we made specific modifications to the simulated RL robot, and analyzed and evaluated its learning behavior in four additional experiments with human trainers. We report significant improvements on several learning measures. This work demonstrates the importance of understanding the human-teacher/robot-learner partnership in order to design algorithms that support how people want to teach while simultaneously improving the robot’s learning behavior.},
  timestamp = {2016-10-13T13:13:52Z},
  author = {Thomaz, Andrea L. and Breazeal, Cynthia},
  file = {Citeseer - Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/4IVIW8F7/Thomaz and Breazeal - Teachable Robots Understanding Human Teaching Beh.pdf:application/pdf;Citeseer - Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/KFFPPCA2/Thomaz and Breazeal - Teachable Robots Understanding Human Teaching Beh.pdf:application/pdf;Citeseer - Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/UA9XAC85/Thomaz et Breazeal - Teachable Robots Understanding Human Teaching Beh.pdf:application/pdf;Citeseer - Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/8WSCMA69/Thomaz and Breazeal - Teachable Robots Understanding Human Teaching Beh.html:text/html;Citeseer - Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/HBN7A5NC/Thomaz and Breazeal - Teachable Robots Understanding Human Teaching Beh.html:text/html;Citeseer - Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/KAHJIG7E/summary.html:text/html}
}

@inproceedings{abbeel2004,
  title = {Apprenticeship Learning via Inverse Reinforcement Learning},
  url = {http://dl.acm.org/citation.cfm?id=1015430},
  timestamp = {2017-01-10T14:37:16Z},
  booktitle = {Proceedings of the Twenty-First International Conference on {{Machine}} Learning},
  publisher = {{ACM}},
  author = {Abbeel, Pieter and Ng, Andrew Y.},
  urldate = {2016-10-31},
  date = {2004},
  pages = {1},
  note = {ICML},
  file = {[PDF] wustl.edu:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/TMKRGXE5/Abbeel et Ng - 2004 - Apprenticeship learning via inverse reinforcement .pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/UEWUXVAZ/citation.html:text/html}
}

@article{zhang2015,
  title = {Towards {{Vision}}-{{Based Deep Reinforcement Learning}} for {{Robotic Motion Control}}},
  url = {http://arxiv.org/abs/1511.03791},
  abstract = {This paper introduces a machine learning based system for controlling a robotic manipulator with visual perception only. The capability to autonomously learn robot controllers solely from raw-pixel images and without any prior knowledge of configuration is shown for the first time. We build upon the success of recent deep reinforcement learning and develop a system for learning target reaching with a three-joint robot manipulator using external visual observation. A Deep Q Network (DQN) was demonstrated to perform target reaching after training in simulation. Transferring the network to real hardware and real observation in a naive approach failed, but experiments show that the network works when replacing camera images with synthetic images.},
  timestamp = {2016-10-20T08:09:38Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1511.03791},
  primaryClass = {cs},
  author = {Zhang, Fangyi and Leitner, Jürgen and Milford, Michael and Upcroft, Ben and Corke, Peter},
  urldate = {2016-10-20},
  date = {2015-11-12},
  keywords = {deep reinforcement learning,robot task learning},
  file = {arXiv\:1511.03791 PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/F6VF6RAH/Zhang et al. - 2015 - Towards Vision-Based Deep Reinforcement Learning f.pdf:application/pdf;arXiv.org Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/5RWB2UGC/1511.html:text/html}
}

@inproceedings{sequeira2016,
  title = {Discovering Social Interaction Strategies for Robots from Restricted-Perception {{Wizard}}-of-{{Oz}} Studies},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7451752},
  timestamp = {2016-11-07T15:04:11Z},
  booktitle = {2016 11th {{ACM}}/{{IEEE International Conference}} on {{Human}}-{{Robot Interaction}} ({{HRI}})},
  publisher = {{IEEE}},
  author = {Sequeira, Pedro and Ribeiro, Tiago and Di Tullio, Eugenio and Petisca, Sofia and Melo, Francisco S. and Castellano, Ginevra and Paiva, Ana and {others}},
  urldate = {2016-11-07},
  date = {2016},
  pages = {197--204}
}

@article{ondruska2016,
  title = {Deep Tracking: {{Seeing}} beyond Seeing Using Recurrent Neural Networks},
  url = {http://arxiv.org/abs/1602.00991},
  shorttitle = {Deep Tracking},
  timestamp = {2016-11-09T21:51:20Z},
  journaltitle = {arXiv preprint arXiv:1602.00991},
  author = {Ondruska, Peter and Posner, Ingmar},
  urldate = {2016-11-09},
  date = {2016}
}

@inproceedings{kulick2013,
  title = {Active {{Learning}} for {{Teaching}} a {{Robot Grounded Relational Symbols}}.},
  url = {http://www.ijcai.org/Proceedings/13/Papers/217.pdf},
  timestamp = {2016-11-23T15:09:13Z},
  booktitle = {{{IJCAI}}},
  author = {Kulick, Johannes and Toussaint, Marc and Lang, Tobias and Lopes, Manuel},
  urldate = {2016-11-23},
  date = {2013}
}

@article{schaul2015,
  title = {Prioritized {{Experience Replay}}},
  url = {http://arxiv.org/abs/1511.05952},
  abstract = {Experience replay lets online reinforcement learning agents remember and reuse experiences from the past. In prior work, experience transitions were uniformly sampled from a replay memory. However, this approach simply replays transitions at the same frequency that they were originally experienced, regardless of their significance. In this paper we develop a framework for prioritizing experience, so as to replay important transitions more frequently, and therefore learn more efficiently. We use prioritized experience replay in Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved human-level performance across many Atari games. DQN with prioritized experience replay achieves a new state-of-the-art, outperforming DQN with uniform replay on 41 out of 49 games.},
  timestamp = {2016-10-14T12:29:11Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1511.05952},
  primaryClass = {cs},
  author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  urldate = {2016-10-10},
  date = {2015-11-18},
  keywords = {Computer Science - Learning},
  file = {arXiv\:1511.05952 PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/KK4BCC87/Schaul et al. - 2015 - Prioritized Experience Replay.pdf:application/pdf;arXiv\:1511.05952 PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/UHG7N85R/Schaul et al. - 2015 - Prioritized Experience Replay.pdf:application/pdf;arXiv.org Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/3SHGNA7B/1511.html:text/html;arXiv.org Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/886CSXSE/1511.html:text/html}
}

@inproceedings{ullman2009,
  title = {Help or Hinder: {{Bayesian}} Models of Social Goal Inference},
  url = {http://papers.nips.cc/paper/3747-help-or-hinder-bayesian-models-of-social-goal-inference},
  shorttitle = {Help or Hinder},
  timestamp = {2016-12-13T11:38:39Z},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Ullman, Tomer and Baker, Chris and Macindoe, Owen and Evans, Owain and Goodman, Noah and Tenenbaum, Joshua B.},
  urldate = {2016-12-13},
  date = {2009},
  pages = {1874--1882},
  file = {Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/5UBT8NAV/3747-help-or-hinder-bayesian-models-of-social-goal-inference.html:text/html}
}

@article{james2016,
  title = {{{3D Simulation}} for {{Robot Arm Control}} with {{Deep Q}}-{{Learning}}},
  url = {http://arxiv.org/abs/1609.03759},
  abstract = {Intelligent control of robotic arms has huge potential over the coming years, but as of now will often fail to adapt when presented with new and unfamiliar environments. Recent trends to solve this problem have seen a shift to end-to-end solutions using deep reinforcement learning to learn policies from visual input, rather than relying on a handcrafted, modular pipeline. Building upon the recent success of deep Q-networks, we present an approach which uses three-dimensional simulations to train a 7-DOF robotic arm in a robot arm control task without any prior knowledge. Policies accept images of the environment as input and output motor actions. However, the high-dimensionality of the policies as well as the large state space makes policy search difficult. This is overcome by ensuring interesting states are explored via intermediate rewards that guide the policy towards higher reward states. Our results demonstrate that deep Q-networks can be used to learn policies for a task that involves locating a cube, grasping, and then finally lifting. The agent is able to learn to deal with a range of starting joint configurations and starting cube positions when tested in simulation. Moreover, we show that policies trained via simulation have the potential to be directly applied to real-world equivalents without any further training. We believe that robot simulations can decrease the dependency on physical robots and ultimately improve productivity of training robot control tasks.},
  timestamp = {2016-10-18T13:21:39Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1609.03759},
  primaryClass = {cs},
  author = {James, Stephen and Johns, Edward},
  urldate = {2016-10-18},
  date = {2016-09-13},
  keywords = {deep reinforcement learning,robot task learning},
  file = {arXiv\:1609.03759 PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/2XKU5IZ2/James et Johns - 2016 - 3D Simulation for Robot Arm Control with Deep Q-Le.pdf:application/pdf;arXiv.org Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/WQRKPT9U/1609.html:text/html}
}

@online{zotero-null-168,
  url = {http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=BA7F5D9528CCCE140FBF90C8C7616180?doi=10.1.1.114.4996&rep=rep1&type=pdf},
  timestamp = {2016-10-31T12:40:41Z},
  urldate = {2016-10-31},
  file = {download\;jsessionid=BA7F5D9528CCCE140FBF90C8C7616180.html:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/HBGT3875/download\;jsessionid=BA7F5D9528CCCE140FBF90C8C7616180.html:text/html}
}

@article{vinciarelli2009,
  title = {Social Signal Processing: {{Survey}} of an Emerging Domain},
  volume = {27},
  issn = {0262-8856},
  url = {http://www.sciencedirect.com/science/article/pii/S0262885608002485},
  doi = {10.1016/j.imavis.2008.11.007},
  shorttitle = {Social Signal Processing},
  abstract = {The ability to understand and manage social signals of a person we are communicating with is the core of social intelligence. Social intelligence is a facet of human intelligence that has been argued to be indispensable and perhaps the most important for success in life. This paper argues that next-generation computing needs to include the essence of social intelligence – the ability to recognize human social signals and social behaviours like turn taking, politeness, and disagreement – in order to become more effective and more efficient. Although each one of us understands the importance of social signals in everyday life situations, and in spite of recent advances in machine analysis of relevant behavioural cues like blinks, smiles, crossed arms, laughter, and similar, design and development of automated systems for social signal processing (SSP) are rather difficult. This paper surveys the past efforts in solving these problems by a computer, it summarizes the relevant findings in social psychology, and it proposes a set of recommendations for enabling the development of the next generation of socially aware computing.},
  timestamp = {2016-10-10T13:54:29Z},
  number = {12},
  journaltitle = {Image and Vision Computing},
  series = {Visual and multimodal analysis of human spontaneous behaviour:},
  author = {Vinciarelli, Alessandro and Pantic, Maja and Bourlard, Hervé},
  urldate = {2016-10-10},
  date = {2009-11},
  pages = {1743--1759},
  file = {ScienceDirect Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/2XRDCB9U/Vinciarelli et al. - 2009 - Social signal processing Survey of an emerging do.pdf:application/pdf;ScienceDirect Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/PQJH4KNG/S0262885608002485.html:text/html}
}

@article{noda2014a,
  title = {Multimodal Integration Learning of Robot Behavior Using Deep Neural Networks},
  volume = {62},
  url = {http://www.sciencedirect.com/science/article/pii/S0921889014000396},
  timestamp = {2016-11-23T10:23:33Z},
  number = {6},
  journaltitle = {Robotics and Autonomous Systems},
  author = {Noda, Kuniaki and Arie, Hiroaki and Suga, Yuki and Ogata, Tetsuya},
  urldate = {2016-11-23},
  date = {2014},
  pages = {721--736}
}

@article{santoro2016,
  title = {One-Shot {{Learning}} with {{Memory}}-{{Augmented Neural Networks}}},
  url = {http://arxiv.org/abs/1605.06065},
  timestamp = {2016-11-17T11:14:26Z},
  journaltitle = {arXiv preprint arXiv:1605.06065},
  author = {Santoro, Adam and Bartunov, Sergey and Botvinick, Matthew and Wierstra, Daan and Lillicrap, Timothy},
  urldate = {2016-11-17},
  date = {2016}
}

@article{schillaci2016,
  title = {Exploration {{Behaviors}}, {{Body Representations}}, and {{Simulation Processes}} for the {{Development}} of {{Cognition}} in {{Artificial Agents}}},
  url = {http://journal.frontiersin.org/article/10.3389/frobt.2016.00039/full},
  doi = {10.3389/frobt.2016.00039},
  abstract = {Sensorimotor control and learning are fundamental prerequisites for cognitive development in humans and animals. Evidence from behavioral sciences and neuroscience suggests that motor and brain development are strongly intertwined with the experiential process of exploration, where internal body representations are formed and maintained over time. In order to guide our movements, our brain must hold an internal model of our body and constantly monitor its configuration state. How can sensorimotor control enable the development of more complex cognitive and motor capabilities? Although a clear answer has still not been found for this question, several studies suggest that processes of mental simulation of action–perception loops are likely to be executed in our brain and are dependent on internal body representations. Therefore, the capability to re-enact sensorimotor experience might represent a key mechanism behind the implementation of higher cognitive capabilities, such as behavior recognition, arbitration and imitation, sense of agency, and self–other distinction. This work is mainly addressed to researchers in autonomous motor and mental development for artificial agents. In particular, it aims at gathering the latest developments in the studies on exploration behaviors, internal body representations, and processes of sensorimotor simulations. Relevant studies in human and animal sciences are discussed and a parallel to similar investigations in robotics is presented.},
  timestamp = {2016-11-09T17:29:40Z},
  journaltitle = {Front. Robot. AI},
  author = {Schillaci, Guido and Hafner, Verena V. and Lara, Bruno},
  urldate = {2016-11-09},
  date = {2016},
  pages = {39},
  keywords = {body representations,developmental robotics,exploration behaviors,internal models,sensorimotor learning,sensorimotor simulations}
}

@article{mordatch,
  title = {Combining {{Model}}-{{Based Policy Search}} with {{Online Model Learning}} for {{Control}} of {{Physical Humanoids}}},
  url = {http://www.cs.berkeley.edu/~pabbeel/papers/2016-ICRA-darwin.pdf},
  timestamp = {2016-11-09T22:20:23Z},
  author = {Mordatch, Igor and Mishra, Nikhil and Eppner, Clemens and Abbeel, Pieter},
  urldate = {2016-11-09}
}

@inproceedings{paletta2007,
  title = {Perception and Developmental Learning of Affordances in Autonomous Robots},
  url = {http://link.springer.com/chapter/10.1007/978-3-540-74565-5_19},
  timestamp = {2016-12-05T12:21:29Z},
  booktitle = {Annual {{Conference}} on {{Artificial Intelligence}}},
  publisher = {{Springer}},
  author = {Paletta, Lucas and Fritz, Gerald and Kintzler, Florian and Irran, Jörg and Dorffner, Georg},
  urldate = {2016-12-05},
  date = {2007},
  pages = {235--250}
}

@article{ugur2015,
  title = {Staged Development of Robot Skills: {{Behavior}} Formation, Affordance Learning and Imitation with Motionese},
  volume = {7},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7094253},
  shorttitle = {Staged Development of Robot Skills},
  timestamp = {2016-11-13T21:16:05Z},
  number = {2},
  journaltitle = {IEEE Transactions on Autonomous Mental Development},
  author = {Ugur, Emre and Nagai, Yukie and Sahin, Erol and Oztop, Erhan},
  urldate = {2016-11-13},
  date = {2015},
  pages = {119--139}
}

@article{tomasello2005,
  title = {Understanding and Sharing Intentions: The Origins of Cultural Cognition},
  volume = {28},
  issn = {0140-525X},
  doi = {10.1017/S0140525X05000129},
  shorttitle = {Understanding and Sharing Intentions},
  abstract = {We propose that the crucial difference between human cognition and that of other species is the ability to participate with others in collaborative activities with shared goals and intentions: shared intentionality. Participation in such activities requires not only especially powerful forms of intention reading and cultural learning, but also a unique motivation to share psychological states with others and unique forms of cognitive representation for doing so. The result of participating in these activities is species-unique forms of cultural cognition and evolution, enabling everything from the creation and use of linguistic symbols to the construction of social norms and individual beliefs to the establishment of social institutions. In support of this proposal we argue and present evidence that great apes (and some children with autism) understand the basics of intentional action, but they still do not participate in activities involving joint intentions and attention (shared intentionality). Human children's skills of shared intentionality develop gradually during the first 14 months of life as two ontogenetic pathways intertwine: (1) the general ape line of understanding others as animate, goal-directed, and intentional agents; and (2) a species-unique motivation to share emotions, experience, and activities with other persons. The developmental outcome is children's ability to construct dialogic cognitive representations, which enable them to participate in earnest in the collectivity that is human cognition.},
  timestamp = {2016-10-20T10:28:46Z},
  langid = {english},
  number = {5},
  journaltitle = {Behav Brain Sci},
  author = {Tomasello, Michael and Carpenter, Malinda and Call, Josep and Behne, Tanya and Moll, Henrike},
  date = {2005-10},
  pages = {675--691; discussion 691--735},
  file = {toward-a-construction-based-account-of-shared-intentions-in-social-cognition.pdf:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/IJKCB2R6/toward-a-construction-based-account-of-shared-intentions-in-social-cognition.pdf:application/pdf},
  eprinttype = {pmid},
  eprint = {16262930}
}

@online{zotero-null-692,
  title = {Better Bibtex Abbreviation - {{Recherche Google}}},
  url = {https://www.google.fr/search?sourceid=chrome-psyapi2&ion=1&espv=2&ie=UTF-8&q=better%20bibtex%20abbreviation&oq=better%20bibtex%20abbreviation&aqs=chrome..69i57j69i60l2.10107j0j1},
  timestamp = {2017-01-10T13:28:01Z},
  urldate = {2017-01-10},
  file = {better bibtex abbreviation - Recherche Google:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/6E4336SF/search.html:text/html}
}

@inproceedings{chavez-garcia2016,
  title = {Discovering and {{Manipulating Affordances}}},
  url = {https://hal.archives-ouvertes.fr/hal-01391427/},
  timestamp = {2016-11-23T10:21:03Z},
  booktitle = {International {{Symposium}} on {{Experimental Robotics}} ({{ISER}} 2016)},
  author = {Chavez-Garcia, Omar and Andries, Mihai and Luce-Vayrac, Pierre and Chatila, Raja},
  urldate = {2016-11-23},
  date = {2016}
}

@inproceedings{memisevic2010,
  title = {Gated Softmax Classification},
  url = {http://papers.nips.cc/paper/3895-gated-softmax-classification},
  timestamp = {2016-10-31T14:39:52Z},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Memisevic, Roland and Zach, Christopher and Pollefeys, Marc and Hinton, Geoffrey E.},
  urldate = {2016-10-31},
  date = {2010},
  pages = {1603--1611}
}

@inproceedings{rolf2012a,
  title = {Explorative Learning of Right Inverse Functions: Theoretical Implications of Redundancy},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.680.6041&rep=rep1&type=pdf#page=6},
  shorttitle = {Explorative Learning of Right Inverse Functions},
  timestamp = {2016-12-02T10:25:00Z},
  booktitle = {Workshop {{New Challenges}} in {{Neural Computation}} 2012},
  publisher = {{Citeseer}},
  author = {Rolf, Matthias and Steil, Jochen J.},
  urldate = {2016-12-02},
  date = {2012},
  pages = {6}
}

@inproceedings{peltason2010,
  location = {{Stroudsburg, PA, USA}},
  title = {Pamini: {{A Framework}} for {{Assembling Mixed}}-Initiative {{Human}}-Robot {{Interaction}} from {{Generic Interaction Patterns}}},
  isbn = {978-1-932432-85-5},
  url = {http://dl.acm.org/citation.cfm?id=1944506.1944546},
  shorttitle = {Pamini},
  abstract = {Dialog modeling in robotics suffers from lack of generalizability, due to the fact that the dialog is heavily influenced by the tasks the robot is able to perform. We introduce interleaving interaction patterns together with a general protocol for task communication which enables us to systematically specify the relationship between dialog structure and task structure. We argue that this approach meets the requirements of advanced dialog modeling on robots and at the same time exhibits a better scalability than existing concepts.},
  timestamp = {2016-10-20T11:57:04Z},
  booktitle = {Proceedings of the 11th {{Annual Meeting}} of the {{Special Interest Group}} on {{Discourse}} and {{Dialogue}}},
  series = {SIGDIAL '10},
  publisher = {{Association for Computational Linguistics}},
  author = {Peltason, Julia and Wrede, Britta},
  urldate = {2016-10-20},
  date = {2010},
  pages = {229--232},
  file = {ACM Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/EXA2RE4Q/Peltason et Wrede - 2010 - Pamini A Framework for Assembling Mixed-initiativ.pdf:application/pdf}
}

@article{papadimitriou,
  title = {The {{Goal Behind}} the {{Action}}: {{Towards Goal}}-Aware {{Systems}} and {{Applications}}},
  url = {https://disi.unitn.it/~velgias/docs/PapadimitriouKMV16.pdf},
  shorttitle = {The {{Goal Behind}} the {{Action}}},
  timestamp = {2016-10-28T12:17:42Z},
  author = {Papadimitriou, Dimitra and Koutrika, Georgia and Mylopoulos, John and Velegrakis, Yannis},
  urldate = {2016-10-28}
}

@article{baranes2013a,
  title = {Active Learning of Inverse Models with Intrinsically Motivated Goal Exploration in Robots},
  volume = {61},
  url = {http://www.sciencedirect.com/science/article/pii/S0921889012000644},
  timestamp = {2016-10-31T13:52:04Z},
  number = {1},
  journaltitle = {Robotics and Autonomous Systems},
  author = {Baranes, Adrien and Oudeyer, Pierre-Yves},
  urldate = {2016-10-31},
  date = {2013},
  pages = {49--73},
  file = {[PDF] arxiv.org:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/E96FX9FA/Baranes et Oudeyer - 2013 - Active learning of inverse models with intrinsical.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/44HKI7VD/S0921889012000644.html:text/html}
}

@article{wolpert2003,
  title = {A Unifying Computational Framework for Motor Control and Social Interaction},
  volume = {358},
  url = {http://rstb.royalsocietypublishing.org/content/358/1431/593.short},
  timestamp = {2016-10-31T14:11:23Z},
  number = {1431},
  journaltitle = {Philosophical Transactions of the Royal Society of London B: Biological Sciences},
  author = {Wolpert, Daniel M. and Doya, Kenji and Kawato, Mitsuo},
  urldate = {2016-10-31},
  date = {2003},
  pages = {593--602},
  file = {[PDF] nih.gov:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/UH9KM7DV/Wolpert et al. - 2003 - A unifying computational framework for motor contr.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/DV44C9GK/593.html:text/html}
}

@inproceedings{chentanez2004,
  title = {Intrinsically Motivated Reinforcement Learning},
  url = {http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2005_724.pdf},
  timestamp = {2017-01-10T10:13:06Z},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Chentanez, Nuttapong and Barto, Andrew G. and Singh, Satinder P.},
  urldate = {2016-12-08},
  date = {2004},
  pages = {1281--1288}
}

@inproceedings{stark2008,
  title = {Functional Object Class Detection Based on Learned Affordance Cues},
  url = {http://link.springer.com/chapter/10.1007/978-3-540-79547-6_42},
  timestamp = {2016-11-25T10:12:38Z},
  booktitle = {International Conference on Computer Vision Systems},
  publisher = {{Springer}},
  author = {Stark, Michael and Lies, Philipp and Zillich, Michael and Wyatt, Jeremy and Schiele, Bernt},
  urldate = {2016-11-25},
  date = {2008},
  pages = {435--444}
}

@inproceedings{niculescu-mizil2007,
  title = {Inductive {{Transfer}} for {{Bayesian Network Structure Learning}}.},
  url = {http://www.jmlr.org/proceedings/papers/v2/niculescu-mizil07a/niculescu-mizil07a.pdf},
  timestamp = {2016-10-31T13:10:07Z},
  booktitle = {{{AISTATS}}},
  author = {Niculescu-Mizil, Alexandru and Caruana, Rich},
  urldate = {2016-10-31},
  date = {2007},
  pages = {339--346},
  file = {[PDF] jmlr.org:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/T7CVH6RW/Niculescu-Mizil et Caruana - 2007 - Inductive Transfer for Bayesian Network Structure .pdf:application/pdf}
}

@inproceedings{kim2015,
  title = {Human-{{Robot Interaction}} Using {{Intention Recognition}}},
  url = {http://dl.acm.org/citation.cfm?id=2815002},
  timestamp = {2016-11-07T15:02:28Z},
  booktitle = {Proceedings of the 3rd {{International Conference}} on {{Human}}-{{Agent Interaction}}},
  publisher = {{ACM}},
  author = {Kim, Sangwook and Yu, Zhibin and Kim, Jonghong and Ojha, Amitash and Lee, Minho},
  urldate = {2016-11-07},
  date = {2015},
  pages = {299--302}
}

@article{blundell2015,
  title = {Weight Uncertainty in Neural Networks},
  url = {http://arxiv.org/abs/1505.05424},
  timestamp = {2016-11-17T12:18:02Z},
  journaltitle = {arXiv preprint arXiv:1505.05424},
  author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
  urldate = {2016-11-17},
  date = {2015}
}

@inproceedings{ivaldi2012,
  title = {Perception and Human Interaction for Developmental Learning of Objects and Affordances},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6651528},
  timestamp = {2016-11-13T16:42:58Z},
  booktitle = {2012 12th {{IEEE}}-{{RAS International Conference}} on {{Humanoid Robots}} ({{Humanoids}} 2012)},
  publisher = {{IEEE}},
  author = {Ivaldi, Serena and Lyubova, Natalia and Gérardeaux-Viret, Damien and Droniou, Alain and Anzalone, Salvatore M. and Chetouani, Mohamed and Filliat, David and Sigaud, Olivier},
  urldate = {2016-11-13},
  date = {2012},
  pages = {248--254}
}

@inproceedings{saomainguyen2013,
  title = {Learning to Recognize Objects through Curiositydriven Manipulation with the Icub Humanoid Robot},
  url = {http://sites.isir.upmc.fr/www/files/2013ACTI2863.pdf},
  timestamp = {2016-11-13T16:36:19Z},
  booktitle = {{{IEEE International Conference}} on {{Development}} and {{Learning}}-{{Epirob}}},
  author = {Sao Mai Nguyen, Serena Ivaldi and Lyubova, Natalia and Droniou, Alain and Gerardeaux-Viret, Damien and Filliat, David and Padois, Vincent and Sigaud, Olivier and Oudeyer, Pierre-Yves},
  urldate = {2016-11-13},
  date = {2013}
}

@inproceedings{nicolescu2003,
  title = {Natural Methods for Robot Task Learning: {{Instructive}} Demonstrations, Generalization and Practice},
  url = {http://dl.acm.org/citation.cfm?id=860614},
  shorttitle = {Natural Methods for Robot Task Learning},
  timestamp = {2016-11-03T15:57:43Z},
  booktitle = {Proceedings of the Second International Joint Conference on {{Autonomous}} Agents and Multiagent Systems},
  publisher = {{ACM}},
  author = {Nicolescu, Monica N. and Mataric, Maja J.},
  urldate = {2016-11-03},
  date = {2003},
  pages = {241--248}
}

@incollection{lesh1999,
  title = {Using Plan Recognition in Human-Computer Collaboration},
  url = {http://link.springer.com/chapter/10.1007/978-3-7091-2490-1_3},
  timestamp = {2016-10-28T12:14:13Z},
  booktitle = {{{UM99 User Modeling}}},
  publisher = {{Springer}},
  author = {Lesh, Neal and Rich, Charles and Sidner, Candace L.},
  urldate = {2016-10-28},
  date = {1999},
  pages = {23--32},
  file = {[PDF] merl.com:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/IWXMRC28/Lesh et al. - 1999 - Using plan recognition in human-computer collabora.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/GQ6X8NRQ/978-3-7091-2490-1_3.html:text/html}
}

@inproceedings{yu2010,
  title = {Investigating Multimodal Real-Time Patterns of Joint Attention in an Hri Word Learning Task},
  url = {http://dl.acm.org/citation.cfm?id=1734561},
  timestamp = {2016-11-07T17:19:41Z},
  booktitle = {Proceedings of the 5th {{ACM}}/{{IEEE}} International Conference on {{Human}}-Robot Interaction},
  publisher = {{IEEE Press}},
  author = {Yu, Chen and Scheutz, Matthias and Schermerhorn, Paul},
  urldate = {2016-11-07},
  date = {2010},
  pages = {309--316}
}

@inproceedings{rohlfing2013,
  title = {Learning New Words in Unfamiliar Frames from Direct and Indirect Teaching},
  url = {https://www.researchgate.net/publication/261710060_Learning_new_words_in_unfamiliar_frames_from_direct_and_indirect_teaching},
  abstract = {In our study, we aimed at investigating how two years old children make use of the prag-matics in order to learn new words from an ongoing interaction. We operationalized the situational...},
  eventtitle = {17th Workshop on the Semantics and Pragmatics of Dialogue (DialDam)},
  timestamp = {2016-10-20T11:57:44Z},
  booktitle = {{{ResearchGate}}},
  author = {Rohlfing, Katharina J. and Poblete, Juana Salas and Joublin, Frank},
  urldate = {2016-10-20},
  date = {2013-12-16},
  file = {Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/B4JHIFDF/Rohlfing et al. - 2013 - Learning new words in unfamiliar frames from direc.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/U93AU8A8/261710060_Learning_new_words_in_unfamiliar_frames_from_direct_and_indirect_teaching.html:text/html}
}

@article{vogt2010,
  title = {Modeling Social Learning of Language and Skills},
  volume = {16},
  issn = {1064-5462},
  doi = {10.1162/artl_a_00007},
  abstract = {We present a model of social learning of both language and skills, while assuming—insofar as possible—strict autonomy, virtual embodiment, and situatedness. This model is built by integrating various previous models of language development and social learning, and it is this integration that, under the mentioned assumptions, provides novel challenges. The aim of the article is to investigate what sociocognitive mechanisms agents should have in order to be able to transmit language from one generation to the next so that it can be used as a medium to transmit internalized rules that represent skill knowledge. We have performed experiments where this knowledge solves the familiar poisonous-food problem. Simulations reveal under what conditions, regarding population structure, agents can successfully solve this problem. In addition to issues relating to perspective taking and mutual exclusivity, we show that agents need to coordinate interactions so that they can establish joint attention in order to form a scaffold for language learning, which in turn forms a scaffold for the learning of rule-based skills. Based on these findings, we conclude by hypothesizing that social learning at one level forms a scaffold for the social learning at another, higher level, thus contributing to the accumulation of cultural knowledge.},
  timestamp = {2016-10-17T15:53:17Z},
  langid = {english},
  number = {4},
  journaltitle = {Artif. Life},
  author = {Vogt, Paul and Haasdijk, Evert},
  date = {2010},
  pages = {289--309},
  keywords = {developmental robotics,interactive learning,language,robot robot interaction,robot task learning},
  file = {alife2010.pdf:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/VB89KUUM/alife2010.pdf:application/pdf},
  eprinttype = {pmid},
  eprint = {20662596}
}

@inproceedings{moulin-frier2013,
  title = {Exploration Strategies in Developmental Robotics: A Unified Probabilistic Framework},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6652535},
  shorttitle = {Exploration Strategies in Developmental Robotics},
  timestamp = {2016-11-23T16:40:44Z},
  booktitle = {2013 {{IEEE Third Joint International Conference}} on {{Development}} and {{Learning}} and {{Epigenetic Robotics}} ({{ICDL}})},
  publisher = {{IEEE}},
  author = {Moulin-Frier, Clément and Oudeyer, Pierre-Yves},
  urldate = {2016-11-23},
  date = {2013},
  pages = {1--6}
}

@article{pitti2013,
  title = {Neural Model for Learning-to-Learn of Novel Task Sets in the Motor Domain},
  volume = {4},
  issn = {1664-1078},
  url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2013.00771/abstract},
  doi = {10.3389/fpsyg.2013.00771},
  timestamp = {2016-10-24T13:11:14Z},
  journaltitle = {Frontiers in Psychology},
  author = {Pitti, Alexandre and Braud, Raphaël and Mahé, Sylvain and Quoy, Mathias and Gaussier, Philippe},
  urldate = {2016-10-24},
  date = {2013},
  file = {fpsyg-04-00771.pdf:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/NPWCGUCH/fpsyg-04-00771.pdf:application/pdf}
}

@article{vallverdu2016,
  title = {Emotional Affordances for Human–robot Interaction},
  url = {http://adb.sagepub.com/content/early/2016/10/09/1059712316668238.abstract},
  timestamp = {2016-11-07T15:03:26Z},
  journaltitle = {Adaptive Behavior},
  author = {Vallverdú, Jordi and Trovato, Gabriele},
  urldate = {2016-11-07},
  date = {2016},
  pages = {1059712316668238}
}

@book{yamashita2008,
  title = {Emergence of {{Functional Hierarchy}} in a {{Multiple Timescale Neural Network Model}}: {{A Humanoid Robot Experiment}}},
  url = {http://neurorobot.kaist.ac.kr/publications/pdf_files/PLoSCB_2008_corrected.pdf},
  shorttitle = {Emergence of {{Functional Hierarchy}} in a {{Multiple Timescale Neural Network Model}}},
  timestamp = {2016-10-31T13:50:09Z},
  publisher = {{PLoS}},
  author = {Yamashita, Y. and Tani, J. and Sporns, Olaf},
  urldate = {2016-10-31},
  date = {2008},
  file = {[PDF] kaist.ac.kr:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/B8D3PUZ5/Yamashita et al. - 2008 - Emergence of Functional Hierarchy in a Multiple Ti.pdf:application/pdf}
}

@article{wang2016,
  title = {Towards {{Bayesian Deep Learning}}: {{A Survey}}},
  url = {http://arxiv.org/abs/1604.01662},
  shorttitle = {Towards {{Bayesian Deep Learning}}},
  timestamp = {2016-11-16T11:43:22Z},
  journaltitle = {arXiv preprint arXiv:1604.01662},
  author = {Wang, Hao and Yeung, Dit-Yan},
  urldate = {2016-11-16},
  date = {2016}
}

@article{dominey2007,
  title = {Towards a Construction-Based Framework for Development of Language, Event Perception and Social Cognition: {{Insights}} from Grounded Robotics and Simulation},
  volume = {70},
  issn = {0925-2312},
  url = {http://www.sciencedirect.com/science/article/pii/S0925231206005182},
  doi = {10.1016/j.neucom.2006.02.030},
  shorttitle = {Towards a Construction-Based Framework for Development of Language, Event Perception and Social Cognition},
  abstract = {The current research addresses the question of how neurocomputational mechanisms developed for a given cognitive function can be adapted to novel functions. In this context, research in language development has contributed to the concept of grammatical construction defined in terms of a functional mapping between the surface structure of an utterance, and its meaning. The objective of the current research is to generalize this notion of construction, and demonstrate its possible application in two cognitive areas that are adjacent and related to language, notably the understanding of physical events based on vision, and the understanding of the intentions of other agents based on observation of their behavior in the context of a perceptually grounded robotic system.},
  timestamp = {2016-10-20T11:56:19Z},
  issue = {13–15},
  journaltitle = {Neurocomputing},
  series = {Selected papers from the 3rd International Conference on Development and Learning (ICDL 2004)Time series prediction competition: the CATS benchmark3rd International Conference on Development and Learning},
  author = {Dominey, Peter Ford},
  urldate = {2016-10-20},
  date = {2007-08},
  pages = {2288--2302},
  file = {ScienceDirect Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/MPV27TNP/Dominey - 2007 - Towards a construction-based framework for develop.pdf:application/pdf;ScienceDirect Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/EH9H6KH7/S0925231206005182.html:text/html}
}

@article{breazeal2009,
  title = {An {{Embodied Cognition Approach}} to {{Mindreading Skills}} for {{Socially Intelligent Robots}}},
  volume = {28},
  issn = {0278-3649, 1741-3176},
  url = {http://ijr.sagepub.com/content/28/5/656},
  doi = {10.1177/0278364909102796},
  abstract = {Future applications for personal robots motivate research into developing robots that are intelligent in their interactions with people. Toward this goal, in this paper we present an integrated socio-cognitive architecture to endow an anthropomorphic robot with the ability to infer mental states such as beliefs, intents, and desires from the observable behavior of its human partner. The design of our architecture is informed by recent findings from neuroscience and embodies cognition that reveals how living systems leverage their physical and cognitive embodiment through simulation-theoretic mechanisms to infer the mental states of others. We assess the robot's mindreading skills on a suite of benchmark tasks where the robot interacts with a human partner in a cooperative scenario and a learning scenario. In addition, we have conducted human subjects experiments using the same task scenarios to assess human performance on these tasks and to compare the robot's performance with that of people. In the process, our human subject studies also reveal some interesting insights into human behavior.},
  timestamp = {2016-10-20T11:53:38Z},
  langid = {english},
  number = {5},
  journaltitle = {The International Journal of Robotics Research},
  author = {Breazeal, Cynthia and Gray, Jesse and Berlin, Matt},
  urldate = {2016-10-20},
  date = {2009-01-05},
  pages = {656--680},
  file = {Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/3WHQKUBQ/Breazeal et al. - 2009 - An Embodied Cognition Approach to Mindreading Skil.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/HPQ7Z2B4/656.html:text/html}
}

@inproceedings{peltason2009,
  title = {Mixed-Initiative in Human Augmented Mapping},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5152683},
  timestamp = {2016-10-31T14:28:59Z},
  booktitle = {Robotics and {{Automation}}, 2009. {{ICRA}}'09. {{IEEE International Conference}} on},
  publisher = {{IEEE}},
  author = {Peltason, Julia and Siepmann, Frederic HK and Spexard, Thorsten P. and Wrede, Britta and Hanheide, Marc and Topp, Elin A.},
  urldate = {2016-10-31},
  date = {2009},
  pages = {2146--2153},
  file = {[PDF] researchgate.net:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/VH7ANHRT/Peltason et al. - 2009 - Mixed-initiative in human augmented mapping.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/NKZQPQET/5152683.html:text/html}
}

@inproceedings{baker2008,
  title = {Theory-Based Social Goal Inference},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.154.2746&rep=rep1&type=pdf},
  timestamp = {2016-12-13T11:38:18Z},
  booktitle = {Proceedings of the Thirtieth Annual Conference of the Cognitive Science Society},
  publisher = {{Citeseer}},
  author = {Baker, Chris L. and Goodman, Noah D. and Tenenbaum, Joshua B.},
  urldate = {2016-12-13},
  date = {2008},
  pages = {1447--1452}
}

@article{scassellati,
  title = {Theory of {{Mind}} for a {{Humanoid Robot}}},
  volume = {12},
  issn = {0929-5593, 1573-7527},
  url = {http://link.springer.com/article/10.1023/A:1013298507114},
  doi = {10.1023/A:1013298507114},
  abstract = {If we are to build human-like robots that can interact naturally with people, our robots must know not only about the properties of objects but also the properties of animate agents in the world. One of the fundamental social skills for humans is the attribution of beliefs, goals, and desires to other people. This set of skills has often been called a “theory of mind.” This paper presents the theories of Leslie (1994) and Baron-Cohen (1995) on the development of theory of mind in human children and discusses the potential application of both of these theories to building robots with similar capabilities. Initial implementation details and basic skills (such as finding faces and eyes and distinguishing animate from inanimate stimuli) are introduced. I further speculate on the usefulness of a robotic implementation in evaluating and comparing these two models.},
  timestamp = {2016-10-24T12:35:09Z},
  langid = {english},
  number = {1},
  journaltitle = {Autonomous Robots},
  author = {Scassellati, Brian},
  urldate = {2016-10-24},
  pages = {13--24},
  file = {Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/PQURIDVU/Scassellati - Theory of Mind for a Humanoid Robot.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/VKRQ9U6Z/A1013298507114.html:text/html}
}

@inproceedings{broz2009,
  title = {Learning Behavior for a Social Interaction Game with a Childlike Humanoid Robot},
  url = {http://robotcub.org/misc/papers/09_Broz_etal.pdf},
  timestamp = {2016-10-31T14:35:37Z},
  booktitle = {Social {{Learning}} in {{Interactive Scenarios Workshop}}, {{Humanoids}}},
  author = {Broz, Frank and Kose-Bagci, Hatice and Nehaniv, Chrystopher L. and Dautenhahn, Kerstin},
  urldate = {2016-10-31},
  date = {2009}
}

@inproceedings{ugur2014a,
  title = {Bootstrapping Paired-Object Affordance Learning with Learned Single-Affordance Features},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6983026},
  timestamp = {2016-11-23T10:18:24Z},
  booktitle = {4th {{International Conference}} on {{Development}} and {{Learning}} and on {{Epigenetic Robotics}}},
  publisher = {{IEEE}},
  author = {Ugur, Emre and Szedmak, Sandor and Piater, Justus},
  urldate = {2016-11-23},
  date = {2014},
  pages = {476--481}
}

@inproceedings{chu2016,
  title = {Learning Object Affordances by Leveraging the Combination of Human-Guidance and Self-Exploration},
  url = {https://www.researchgate.net/publication/301913047_Learning_object_affordances_by_leveraging_the_combination_of_human-guidance_and_self-exploration},
  doi = {10.1109/HRI.2016.7451755},
  abstract = {Official Full-Text Publication: Learning object affordances by leveraging the combination of human-guidance and self-exploration on ResearchGate, the professional network for scientists.},
  eventtitle = {2016 11th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  timestamp = {2016-11-13T21:19:27Z},
  booktitle = {{{ResearchGate}}},
  author = {Chu, Vivian and Fitzgerald, Tesca and Thomaz, Andrea L.},
  urldate = {2016-11-13},
  date = {2016-03-01},
  pages = {221--228}
}

@article{schmidhuber2015,
  title = {On Learning to Think: {{Algorithmic}} Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models},
  url = {http://arxiv.org/abs/1511.09249},
  shorttitle = {On Learning to Think},
  timestamp = {2016-11-07T17:32:02Z},
  journaltitle = {arXiv preprint arXiv:1511.09249},
  author = {Schmidhuber, Juergen},
  urldate = {2016-11-07},
  date = {2015}
}

@inproceedings{boucenna2011,
  title = {Development of Joint Attention and Social Referencing},
  volume = {2},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6037317},
  timestamp = {2016-11-23T13:17:06Z},
  booktitle = {2011 {{IEEE International Conference}} on {{Development}} and {{Learning}} ({{ICDL}})},
  publisher = {{IEEE}},
  author = {Boucenna, Sofiane and Gaussier, Philippe and Hafemeister, Laurence},
  urldate = {2016-11-23},
  date = {2011},
  pages = {1--6}
}

@article{clark2013,
  title = {Whatever next? {{Predictive}} Brains, Situated Agents, and the Future of Cognitive Science},
  volume = {36},
  url = {http://journals.cambridge.org/abstract_S0140525X12000477},
  shorttitle = {Whatever Next?},
  timestamp = {2016-10-31T14:42:43Z},
  issue = {03},
  journaltitle = {Behavioral and Brain Sciences},
  author = {Clark, Andy},
  urldate = {2016-10-31},
  date = {2013},
  pages = {181--204}
}

@incollection{griffith2013,
  title = {Policy {{Shaping}}: {{Integrating Human Feedback}} with {{Reinforcement Learning}}},
  url = {http://papers.nips.cc/paper/5187-policy-shaping-integrating-human-feedback-with-reinforcement-learning.pdf},
  shorttitle = {Policy {{Shaping}}},
  timestamp = {2016-10-20T11:51:56Z},
  booktitle = {Advances in {{Neural Information Processing Systems}} 26},
  publisher = {{Curran Associates, Inc.}},
  author = {Griffith, Shane and Subramanian, Kaushik and Scholz, Jonathan and Isbell, Charles and Thomaz, Andrea L},
  editor = {Burges, C. J. C. and Bottou, L. and Welling, M. and Ghahramani, Z. and Weinberger, K. Q.},
  urldate = {2016-10-20},
  date = {2013},
  pages = {2625--2633},
  file = {NIPS Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/BEAF5U4Z/Griffith et al. - 2013 - Policy Shaping Integrating Human Feedback with Re.pdf:application/pdf;NIPS Snapshort:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/TR5A4EE9/5187-policy-shaping-integrating-human-feedback-with-reinforcement-learning.html:text/html}
}

@article{nehaniv,
  title = {Interaction and {{Experience}} in {{Enactive Intelligence}} and {{Humanoid Robotics}}},
  url = {https://www.researchgate.net/profile/Chrystopher_Nehaniv/publication/236236674_Interaction_and_Experience_in_Enactive_Intelligence_and_Humanoid_Robotics/links/556986af08aec22683033d95.pdf},
  timestamp = {2016-11-07T17:33:09Z},
  author = {Nehaniv, Chrystopher L. and Förster, Frank and Saunders, Joe and Broz, Frank and Antonova, Elena and Köse, Hatice and Lyon, Caroline and Lehmann, Hagen and Sato, Yo and Dautenhahn, Kerstin},
  urldate = {2016-11-07}
}

@article{tzeng2015,
  title = {Towards {{Adapting Deep Visuomotor Representations}} from {{Simulated}} to {{Real Environments}}},
  url = {http://arxiv.org/abs/1511.07111},
  abstract = {We address the problem of adapting robotic perception from simulated to real-world environments. For many robotic control tasks, real training imagery is expensive to obtain, but a large number of synthetic images is easy to generate through simulation. We propose a method that adapts visual representations using a small number of paired synthetic and real views of the same scene. Our model generalizes prior approaches and combines a standard in-domain loss, a cross-domain adaptation loss, and a contrastive loss explicitly designed to align pairs of images in feature space. We presume a synthetic dataset comprised of views that are a superset of a small number of real views, where the alignment may be either explicit or latent. We evaluate our approach on a manipulation task and show that by exploiting the presence of synthetic-real image pairs, our model is able to compensate for domain shift more effectively than conventional initialization techniques. Our results serve as an initial step toward pretraining deep visuomotor policies entirely in simulation, significantly reducing physical demands when learning complex policies.},
  timestamp = {2016-10-20T11:49:16Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1511.07111},
  primaryClass = {cs},
  author = {Tzeng, Eric and Devin, Coline and Hoffman, Judy and Finn, Chelsea and Peng, Xingchao and Levine, Sergey and Saenko, Kate and Darrell, Trevor},
  urldate = {2016-10-20},
  date = {2015-11-23},
  file = {arXiv\:1511.07111 PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/X6F8JS4K/Tzeng et al. - 2015 - Towards Adapting Deep Visuomotor Representations f.pdf:application/pdf;arXiv.org Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/QDBTKUXR/1511.html:text/html}
}

@article{grand2014,
  title = {Synchrony {{Detection}} as a {{Reinforcement Signal}} for {{Learning}}: {{Application}} to {{Human Robot Interaction}}},
  volume = {126},
  issn = {1877-0428},
  url = {http://www.sciencedirect.com/science/article/pii/S1877042814018709},
  doi = {10.1016/j.sbspro.2014.02.322},
  shorttitle = {Synchrony {{Detection}} as a {{Reinforcement Signal}} for {{Learning}}},
  abstract = {The present study is aiming to build a synchrony-based attentional mechanism allowing to initiate and to maintain human robot interactions. Moreover, we question the importance of synchrony detection for learning and gaining new competences through the interaction. We previously proposed a synchrony-based neural model capable of giving the robot minimal abilities to select a human partner and to focus its visual attention on this preferred interactant. Here, we extend this model by using synchrony detection as a reinforcement signal for learning (during the interaction) the human partner appearance (shape) in the context of an autonomous mobile robot.},
  timestamp = {2016-11-07T16:37:22Z},
  journaltitle = {Procedia - Social and Behavioral Sciences},
  series = {International Conference on Timing and Time Perception, 31 March – 3 April 2014, Corfu, Greece},
  author = {Grand, Caroline and Mostafaoui, Ghilès and Hasnain, Syed Khursheed and Gaussier, Philippe},
  urldate = {2016-11-07},
  date = {2014-03-21},
  pages = {82--91},
  keywords = {Dynamical systems,Focus of attention,Intuitive human robot interaction,Neural networks,Partner selection,Synchrony}
}

@inproceedings{lallee2011,
  title = {Towards a Platform-Independent Cooperative Human-Robot Interaction System: {{Ii}}. Perception, Execution and Imitation of Goal Directed Actions},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6094744},
  shorttitle = {Towards a Platform-Independent Cooperative Human-Robot Interaction System},
  timestamp = {2016-10-24T15:26:16Z},
  booktitle = {2011 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  publisher = {{IEEE}},
  author = {Lallée, Stephane and Pattacini, Ugo and Boucher, Jean David and Lemaignan, Séverin and Lenz, Alexander and Melhuish, Chris and Natale, Lorenzo and Skachek, Sergey and Hamann, Katharina and Steinwender, Jasmin and {others}},
  urldate = {2016-10-24},
  date = {2011},
  pages = {2895--2902},
  file = {[PDF] from skadge.org:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/A4EPAVUE/Lallée et al. - 2011 - Towards a platform-independent cooperative human-r.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/HDKZCVE8/6094744.html:text/html}
}

@inproceedings{ugur2015a,
  title = {Bottom-up Learning of Object Categories, Action Effects and Logical Rules: {{From}} Continuous Manipulative Exploration to Symbolic Planning},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7139553},
  shorttitle = {Bottom-up Learning of Object Categories, Action Effects and Logical Rules},
  timestamp = {2016-11-23T10:17:44Z},
  booktitle = {2015 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  publisher = {{IEEE}},
  author = {Ugur, Emre and Piater, Justus},
  urldate = {2016-11-23},
  date = {2015},
  pages = {2627--2633}
}

@inproceedings{osorio2010,
  title = {Gaussian Mixture Models for Affordance Learning Using {{Bayesian Networks}}},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5650297},
  timestamp = {2016-11-23T10:24:11Z},
  booktitle = {Intelligent {{Robots}} and {{Systems}} ({{IROS}}), 2010 {{IEEE}}/{{RSJ International Conference}} on},
  publisher = {{IEEE}},
  author = {Osório, Pedro and Bernardino, Alexandre and Martinez-Cantin, Ruben and Santos-Victor, José},
  urldate = {2016-11-23},
  date = {2010},
  pages = {4432--4437}
}

@article{lever2014,
  title = {Deterministic Policy Gradient Algorithms},
  url = {http://www.jmlr.org/proceedings/papers/v32/silver14.pdf},
  timestamp = {2016-11-02T13:36:47Z},
  author = {Lever, Guy},
  urldate = {2016-11-02},
  date = {2014}
}

@article{rolf,
  title = {Intentional {{Goals}}: {{Affordances}} with {{Values}}?},
  url = {http://vislab.isr.ist.utl.pt/wp-content/uploads/2015/10/RolfAsada2015-Affordance.pdf},
  shorttitle = {Intentional {{Goals}}},
  timestamp = {2016-12-05T12:51:28Z},
  author = {Rolf, Matthias and Asada, Minoru},
  urldate = {2016-12-05}
}

@article{salam2016,
  title = {Fully {{Automatic Analysis}} of {{Engagement}} and {{Its Relationship}} to {{Personality}} in {{Human}}-{{Robot Interactions}}},
  volume = {PP},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2016.2614525},
  abstract = {Engagement is crucial to designing intelligent systems that can adapt to the characteristics of their users. This paper focuses on automatic analysis and classification of engagement based on humans’ and robot’s personality profiles in a triadic human-human-robot interaction setting. More explicitly, we present a study that involves two participants interacting with a humanoid robot, and investigate how participants’ personalities can be used together with the robot’s personality to predict the engagement state of each participant. The fully automatic system is firstly trained to predict the Big Five personality traits of each participant by extracting individual and interpersonal features from their nonverbal behavioural cues. Secondly, the output of the personality prediction system is used as an input to the engagement classification system. Thirdly, we focus on the concept of “group engagement”, which we define as the collective engagement of the participants with the robot, and analyse the impact of similar and dissimilar personalities on the engagement classification. Our experimental results show that (i) using the automatically predicted personality labels for engagement classification yields an F-measure on par with using the manually annotated personality labels, demonstrating the effectiveness of the automatic personality prediction module proposed; (ii) using the individual and interpersonal features without utilising personality information is not sufficient for engagement classification, instead incorporating the participants’ and robot’s personalities with individual/interpersonal features increases engagement classification performance; and (iii) the best classification performance is achieved when the participants and the robot are extroverted, while the worst results are obt- ined when all are introverted.},
  timestamp = {2016-10-10T13:31:19Z},
  number = {99},
  journaltitle = {IEEE Access},
  author = {Salam, H. and Celiktutan, O. and Hupont, I. and Gunes, H. and Chetouani, M.},
  date = {2016},
  pages = {1--1},
  keywords = {human robot interaction,personality,social engagement},
  file = {IEEE Xplore Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/SDE2GJR6/Salam et al. - 2016 - Fully Automatic Analysis of Engagement and Its Rel.pdf:application/pdf;IEEE Xplore Abstract Record:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/N9KUCKAU/7580650.html:text/html}
}

@article{nomikou2016,
  title = {Constructing {{Interaction}}: {{The Development}} of {{Gaze Dynamics}}},
  volume = {25},
  issn = {1522-7219},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/icd.1975/abstract},
  doi = {10.1002/icd.1975},
  shorttitle = {Constructing {{Interaction}}},
  abstract = {Gaze is one of the first and most important means of communication and coordination in parent–infant dyads. In the present paper we used a novel method, designed to discover patterns in time-series, to investigate the dynamics of gaze in dyads and its developmental change. Using a longitudinal corpus of natural interactions, mutual mother–infant gaze was coded when the infants were 3, 6, and 8 months old and subjected to recurrence analysis. The cross-recurrence profiles obtained for the three time points show systematic differences: While the engagement in mutual gaze decreases with age, the behaviour becomes more tightly coupled as a more regular temporal structure emerges. We suggest that this stronger interdependency of gaze behaviour may indicate the development of a social feedback loop enabling engagement in interaction. Copyright © 2016 John Wiley \& Sons, Ltd.},
  timestamp = {2016-10-24T12:40:18Z},
  langid = {english},
  number = {3},
  journaltitle = {Inf. Child. Dev.},
  author = {Nomikou, Iris and Leonardi, Giuseppe and Rohlfing, Karharina J. and Rączaszek-Leonardi, Joanna},
  urldate = {2016-10-24},
  date = {2016-05-01},
  pages = {277--295},
  file = {Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/GBUA7E5W/abstract.html:text/html}
}

@article{pinto2016,
  title = {The {{Curious Robot}}: {{Learning Visual Representations}} via {{Physical Interactions}}},
  url = {http://arxiv.org/abs/1604.01360},
  shorttitle = {The {{Curious Robot}}},
  timestamp = {2016-11-07T15:03:57Z},
  journaltitle = {arXiv preprint arXiv:1604.01360},
  author = {Pinto, Lerrel and Gandhi, Dhiraj and Han, Yuanfeng and Park, Yong-Lae and Gupta, Abhinav},
  urldate = {2016-11-07},
  date = {2016}
}

@article{garnelo2016,
  title = {Towards {{Deep Symbolic Reinforcement Learning}}},
  url = {https://arxiv.org/abs/1609.05518},
  timestamp = {2016-11-17T14:21:16Z},
  journaltitle = {arXiv preprint arXiv:1609.05518},
  author = {Garnelo, Marta and Arulkumaran, Kai and Shanahan, Murray},
  urldate = {2016-11-17},
  date = {2016}
}

@inproceedings{pointeau2013a,
  title = {Embodied Simulation Based on Autobiographical Memory},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-39802-5_21},
  timestamp = {2016-10-24T15:23:47Z},
  booktitle = {Conference on {{Biomimetic}} and {{Biohybrid Systems}}},
  publisher = {{Springer}},
  author = {Pointeau, Gregoire and Petit, Maxime and Dominey, Peter Ford},
  urldate = {2016-10-24},
  date = {2013},
  pages = {240--250},
  file = {551174e80cf24e9311ce59ac.pdf:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/6ETAS2MZ/551174e80cf24e9311ce59ac.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/3UTDGRPC/978-3-642-39802-5_21.html:text/html}
}

@article{natale,
  title = {The {{iCub}} Platform: A Tool for Studying Intrinsically Motivated Learning},
  url = {http://www.isir.upmc.fr/files/2012COS2180.pdf},
  shorttitle = {The {{iCub}} Platform},
  timestamp = {2016-11-13T16:20:28Z},
  author = {Natale, Lorenzo and Nori, Francesco and Metta, Giorgio and Fumagalli, Matteo and Ivaldi, Serena and Pattacini, Ugo and Randazzo, Marco and Schmitz, Alexander and Sandini, Giulio},
  urldate = {2016-11-13}
}

@incollection{ghahramani1998,
  title = {Learning Dynamic {{Bayesian}} Networks},
  url = {http://link.springer.com/chapter/10.1007/BFb0053999},
  timestamp = {2016-10-31T13:08:37Z},
  booktitle = {Adaptive Processing of Sequences and Data Structures},
  publisher = {{Springer}},
  author = {Ghahramani, Zoubin},
  urldate = {2016-10-31},
  date = {1998},
  pages = {168--197},
  file = {[PDF] cam.ac.uk:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/JJQJN6H4/Ghahramani - 1998 - Learning dynamic Bayesian networks.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/U762NIH4/BFb0053999.html:text/html}
}

@inproceedings{vollmer2014a,
  title = {Studying the Co-Construction of Interaction Protocols in Collaborative Tasks with Humans},
  doi = {10.1109/DEVLRN.2014.6982983},
  abstract = {In interaction, humans align and effortlessly create common ground in communication, allowing efficient collaboration in widely diverse contexts. Robots are still far away from being able to adapt in such a flexible manner with non-expert humans to complete collaborative tasks. Challenges include the capability to understand unknown feedback or guidance signals, to make sense of what they refer to depending on their timing and context, and to agree on how to organize the interaction into roles and turns. As a first step in approaching this issue, we investigate here the processes used by humans to negotiate a protocol of interaction when they do not already share one. We introduce a new experimental setup, where two humans have to collaborate to solve a task. The channels of communication they can use are constrained and force them to invent and agree on a shared interaction protocol in order to solve the task. These constraints allow us to analyze how a communication protocol is progressively established through the interplay and history of individual actions. We report preliminary results obtained from a pilot study, and discuss how the understanding of strategies used by humans could be useful to achieve more flexible HRI.},
  eventtitle = {4th International Conference on Development and Learning and on Epigenetic Robotics},
  timestamp = {2016-10-20T11:55:34Z},
  booktitle = {4th {{International Conference}} on {{Development}} and {{Learning}} and on {{Epigenetic Robotics}}},
  author = {Vollmer, A. L. and Grizou, J. and Lopes, M. and Rohlfing, K. and Oudeyer, P. Y.},
  date = {2014-10},
  pages = {208--215},
  file = {IEEE Xplore Full Text PDF:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/SEKGRB7A/Vollmer et al. - 2014 - Studying the co-construction of interaction protoc.pdf:application/pdf;IEEE Xplore Abstract Record:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/KNATHR3Q/6982983.html:text/html}
}

@article{kulkarni2016,
  title = {Hierarchical Deep Reinforcement Learning: {{Integrating}} Temporal Abstraction and Intrinsic Motivation},
  url = {http://arxiv.org/abs/1604.06057},
  shorttitle = {Hierarchical Deep Reinforcement Learning},
  timestamp = {2016-11-07T14:59:55Z},
  journaltitle = {arXiv preprint arXiv:1604.06057},
  author = {Kulkarni, Tejas D. and Narasimhan, Karthik R. and Saeedi, Ardavan and Tenenbaum, Joshua B.},
  urldate = {2016-11-07},
  date = {2016}
}

@article{sarathy,
  title = {Beyond {{Grasping}}-{{Perceiving Affordances Across Various Stages}} of {{Cognitive Development}}},
  volume = {12},
  url = {https://hrilab.tufts.edu/publications/sarathyscheutz2016icdl.pdf},
  timestamp = {2016-11-23T10:20:35Z},
  journaltitle = {framework},
  author = {Sarathy, Vasanth and Scheutz, Matthias},
  urldate = {2016-11-23},
  pages = {13}
}

@inproceedings{cruz2014,
  title = {Improving Reinforcement Learning with Interactive Feedback and Affordances},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6982975},
  timestamp = {2016-12-05T10:07:22Z},
  booktitle = {4th {{International Conference}} on {{Development}} and {{Learning}} and on {{Epigenetic Robotics}}},
  publisher = {{IEEE}},
  author = {Cruz, Francisco and Magg, Sven and Weber, Cornelius and Wermter, Stefan},
  urldate = {2016-12-05},
  date = {2014},
  pages = {165--170}
}

@article{lemme,
  title = {Kinesthetic Teaching of Visuomotor Coordination for Pointing by the Humanoid Robot {{iCub}}},
  url = {https://www.researchgate.net/profile/Guilherme_Barreto2/publication/236246884_Kinesthetic_teaching_of_visuomotor_coordination_for_pointing_by_the_humanoid_robot_iCub/links/00463517581934eb64000000.pdf},
  timestamp = {2016-11-03T15:44:45Z},
  author = {Lemme, Andre and Freire, Ananda and Barreto, Guilherme and Steil, Jochen},
  urldate = {2016-11-03}
}

@inproceedings{torralba2011,
  title = {Learning to Learn with Compound Hd Models},
  url = {http://papers.nips.cc/paper/4474-learning-to-learn-with-compound-hd-models},
  timestamp = {2016-11-25T08:56:31Z},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Torralba, Antonio and Tenenbaum, Joshua B. and Salakhutdinov, Ruslan R.},
  urldate = {2016-11-25},
  date = {2011},
  pages = {2061--2069}
}

@book{neal2012,
  title = {Bayesian Learning for Neural Networks},
  volume = {118},
  url = {https://books.google.ch/books?hl=en&lr=&id=LHHrBwAAQBAJ&oi=fnd&pg=PR3&dq=BAYESIAN+LEARNING+FOR+NEURAL+NETWORKS&ots=K3AhQS5v_a&sig=lNPjC-qCalzhlkL0L1u1dGgZ3ls},
  timestamp = {2016-11-17T12:27:58Z},
  publisher = {{Springer Science \& Business Media}},
  author = {Neal, Radford M.},
  urldate = {2016-11-17},
  date = {2012}
}

@article{montesano2008,
  title = {Learning Object Affordances: {{From}} Sensory–motor Coordination to Imitation},
  volume = {24},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4456755},
  shorttitle = {Learning Object Affordances},
  timestamp = {2016-11-23T10:23:56Z},
  number = {1},
  journaltitle = {IEEE Transactions on Robotics},
  author = {Montesano, Luis and Lopes, Manuel and Bernardino, Alexandre and Santos-Victor, José},
  urldate = {2016-11-23},
  date = {2008},
  pages = {15--26}
}

@incollection{toussaint2010,
  title = {A Bayesian View on Motor Control and Planning},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-05181-4_11},
  timestamp = {2016-10-31T14:19:43Z},
  booktitle = {From {{Motor Learning}} to {{Interaction Learning}} in {{Robots}}},
  publisher = {{Springer}},
  author = {Toussaint, Marc and Goerick, Christian},
  urldate = {2016-10-31},
  date = {2010},
  pages = {227--252},
  file = {[PDF] semanticscholar.org:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/CGCP6SRX/Toussaint et Goerick - 2010 - A bayesian view on motor control and planning.pdf:application/pdf;Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/UM58EQXA/978-3-642-05181-4_11.html:text/html}
}

@article{pasa2015,
  title = {Neural {{Networks}} for {{Sequential Data}}: A {{Pre}}-Training {{Approach}} Based on {{Hidden Markov Models}}},
  volume = {169},
  url = {http://www.sciencedirect.com/science/article/pii/S0925231215003689},
  shorttitle = {Neural {{Networks}} for {{Sequential Data}}},
  timestamp = {2016-10-31T14:45:22Z},
  journaltitle = {Neurocomputing},
  author = {Pasa, Luca and Testolin, Alberto and Sperduti, Alessandro},
  urldate = {2016-10-31},
  date = {2015},
  pages = {323--333}
}

@article{piekniewski2016,
  title = {Unsupervised {{Learning}} from {{Continuous Video}} in a {{Scalable Predictive Recurrent Network}}},
  url = {http://arxiv.org/abs/1607.06854},
  abstract = {Understanding visual reality involves acquiring common-sense knowledge about countless regularities in the visual world, e.g., how illumination alters the appearance of objects in a scene, and how motion changes their apparent spatial relationship. These regularities are hard to label for training supervised machine learning algorithms; consequently, algorithms need to learn these regularities from the real world in an unsupervised way. We present a novel network meta-architecture that can learn world dynamics from raw, continuous video. The components of this network can be implemented using any algorithm that possesses three key capabilities: prediction of a signal over time, reduction of signal dimensionality (compression), and the ability to use supplementary contextual information to inform the prediction. The presented architecture is highly-parallelized and scalable, and is implemented using localized connectivity, processing, and learning. We demonstrate an implementation of this architecture where the components are built from multi-layer perceptrons. We apply the implementation to create a system capable of stable and robust visual tracking of objects as seen by a moving camera. Results show performance on par with or exceeding state-of-the-art tracking algorithms. The tracker can be trained in either fully supervised or unsupervised-then-briefly-supervised regimes. Success of the briefly-supervised regime suggests that the unsupervised portion of the model extracts useful information about visual reality. The results suggest a new class of AI algorithms that uniquely combine prediction and scalability in a way that makes them suitable for learning from and --- and eventually acting within --- the real world.},
  timestamp = {2016-10-10T13:32:19Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1607.06854},
  primaryClass = {cs},
  author = {Piekniewski, Filip and Laurent, Patryk and Petre, Csaba and Richert, Micah and Fisher, Dimitry and Hylton, Todd},
  urldate = {2016-10-10},
  date = {2016-07-22},
  keywords = {_tablet},
  file = {Piekniewski et al_2016_Unsupervised Learning from Continuous Video in a Scalable Predictive Recurrent.pdf:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/I4C7PID6/Piekniewski et al_2016_Unsupervised Learning from Continuous Video in a Scalable Predictive Recurrent.pdf:application/pdf;Piekniewski et al_2016_Unsupervised Learning from Continuous Video in a Scalable Predictive Recurrent.pdf:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/VT4ZZWVH/Piekniewski et al_2016_Unsupervised Learning from Continuous Video in a Scalable Predictive Recurrent.pdf:application/pdf;arXiv.org Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/23WADFBM/1607.html:text/html;arXiv.org Snapshot:/home/pierre/.zotero/zotero/0up8o4qb.default/zotero/storage/FTTCZ2IT/1607.html:text/html}
}

@inproceedings{kose-bagci2008,
  title = {Emergent Dynamics of Turn-Taking Interaction in Drumming Games with a Humanoid Robot},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4600690},
  timestamp = {2016-11-09T17:49:38Z},
  booktitle = {{{RO}}-{{MAN}} 2008-{{The}} 17th {{IEEE International Symposium}} on {{Robot}} and {{Human Interactive Communication}}},
  publisher = {{IEEE}},
  author = {Kose-Bagci, Hatice and Dautenhahn, Kerstin and Nehaniv, Chrystopher L.},
  urldate = {2016-11-09},
  date = {2008},
  pages = {346--353}
}

@incollection{hoffmann2014,
  title = {Minimally Cognitive Robotics: Body Schema, Forward Models, and Sensorimotor Contingencies in a Quadruped Machine},
  url = {http://link.springer.com/chapter/10.1007/978-3-319-05107-9_15},
  shorttitle = {Minimally Cognitive Robotics},
  timestamp = {2016-11-09T17:27:50Z},
  booktitle = {Contemporary {{Sensorimotor Theory}}},
  publisher = {{Springer}},
  author = {Hoffmann, Matej},
  urldate = {2016-11-09},
  date = {2014},
  pages = {209--233}
}

@article{lillicrap2015,
  title = {Continuous Control with Deep Reinforcement Learning},
  url = {http://arxiv.org/abs/1509.02971},
  timestamp = {2016-10-31T14:48:57Z},
  journaltitle = {arXiv preprint arXiv:1509.02971},
  author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  urldate = {2016-10-31},
  date = {2015}
}

@article{oudeyer2007,
  title = {Intrinsic Motivation Systems for Autonomous Mental Development},
  volume = {11},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4141061},
  timestamp = {2016-12-02T10:23:46Z},
  number = {2},
  journaltitle = {IEEE transactions on evolutionary computation},
  author = {Oudeyer, Pierre-Yves and Kaplan, Frdric and Hafner, Verena V.},
  urldate = {2016-12-02},
  date = {2007},
  pages = {265--286}
}

@article{koppula2016,
  title = {Anticipating Human Activities Using Object Affordances for Reactive Robotic Response},
  volume = {38},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7102751},
  timestamp = {2016-11-17T17:23:36Z},
  number = {1},
  journaltitle = {IEEE transactions on pattern analysis and machine intelligence},
  author = {Koppula, Hema S. and Saxena, Ashutosh},
  urldate = {2016-11-17},
  date = {2016},
  pages = {14--29}
}

@article{wulfmeier2015a,
  title = {Deep {{Inverse Reinforcement Learning}}},
  url = {http://arxiv.org/abs/1507.04888},
  timestamp = {2016-11-07T15:00:51Z},
  journaltitle = {arXiv preprint arXiv:1507.04888},
  author = {Wulfmeier, Markus and Ondruska, Peter and Posner, Ingmar},
  urldate = {2016-11-07},
  date = {2015}
}

@comment{jabref-meta: groupsversion:3;}
@comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:active perception\;0\;tagniguchi2015\;;
1 ExplicitGroup:actor critic methods\;0\;bhatnagar2009\;macglashana\;;
1 ExplicitGroup:affordances\;0\;nguyen2016\;ugur2014\;antunes\;sun2010
\;ugur2011\;cruz\;moldovan2013\;antunes2016\;kulick2013\;paletta2007\;
chavez-garcia2016\;stark2008\;ugur2014a\;chu2016\;ugur2015a\;osorio201
0\;rolf\;sarathy\;cruz2014\;montesano2008\;koppula2014\;;
1 ExplicitGroup:anis\;0\;najar2015\;najar2015a\;najar\;;
1 ExplicitGroup:bayesian deep learning\;0\;korattikara2015\;blundell20
15\;wang2016\;torralba2011\;neal2012\;;
1 ExplicitGroup:cognitive developmental learning\;0\;zotero-null-29\;z
otero-null-37\;sigaud2016\;asada2009\;lake2016\;ugur2015\;broz2009\;ga
rnelo2016\;;
1 ExplicitGroup:deep q learning\;0\;mnih2016\;pfau2016\;mnih2015\;hass
elt2010\;zhang2015\;schaul2015\;james2016\;lever2014\;lillicrap2015\;;
1 ExplicitGroup:demonstration\;0\;argall2009\;chernova2007\;;
1 ExplicitGroup:explauto\;0\;moulin-frier2014\;starzyk2016\;moulin-fri
er2013\;;
1 ExplicitGroup:exploration/exploitation\;0\;;
1 ExplicitGroup:exploration in RL\;0\;coborus2013\;subramanian2016\;;
1 ExplicitGroup:from video games\;0\;pointeau2013\;;
1 ExplicitGroup:Generic / misc\;0\;undefined\;steels2008\;lin1992\;und
efined\;undefined\;droniou2015\;undefined\;tomasello2005\;vogt2010\;do
miney2007\;tzeng2015\;lallee2011\;piekniewski2016\;;
1 ExplicitGroup:goal babbling\;0\;rolf2011\;baranes2013\;rolf2014\;sao
mai2014\;rolf2010\;rolf2012\;rolf2012a\;oudeyer2007\;;
1 ExplicitGroup:hiérarchie\;0\;yamashita2008\;;
1 ExplicitGroup:human teaching robots\;0\;oudah2015\;austermann2010\;v
ollmer2014\;cakmak2010\;cederborg2015\;thomaz2006\;loftin2014\;lopes20
11\;zotero-null-55\;grizou2014\;amershi2014\;grizou2013\;teachers\;tho
maz\;nicolescu2003\;griffith2013\;vollmer2014a\;;
1 ExplicitGroup:icub\;0\;natale\;;
1 ExplicitGroup:interactional motivation\;0\;georgeon2012\;georgeon201
3\;;
1 ExplicitGroup:interaction frames\;0\;rohlfing2016\;grizou2014a\;unde
fined\;rohlfing2013\;;
1 ExplicitGroup:intrinsic motivation and RL\;0\;chentanez2004\;;
1 ExplicitGroup:inverse reinforcement learning\;0\;ng2000\;abbeel2004\
;;
1 ExplicitGroup:joint attention\;0\;boucenna2011\;;
1 ExplicitGroup:learning finite state machines\;0\;;
1 ExplicitGroup:maths\;0\;jordan2004\;kording2004\;stulp2013\;zotero-n
ull-168\;toussaint2010\;;
1 ExplicitGroup:memory\;0\;pointeau2014\;pointeau2013a\;;
1 ExplicitGroup:memroy\;0\;zhang2016\;santoro2016\;;
1 ExplicitGroup:multimodal integration\;0\;noda2014a\;;
1 ExplicitGroup:neural nets\;0\;levine2014\;mitchell1993\;memisevic201
0\;pasa2015\;;
1 ExplicitGroup:neurosciences\;0\;pitti2013\;;
1 ExplicitGroup:new\;0\;;
1 ExplicitGroup:object recogntion\;0\;tagniguchi2015a\;ivaldi2012\;sao
mainguyen2013\;;
1 ExplicitGroup:observing=acting\;0\;wolpert2003\;;
1 ExplicitGroup:optimal control\;0\;levine2013\;tassa2008\;watter2015\
;todorov2005\;;
1 ExplicitGroup:Perspective taking\;0\;dominey2011\;trafton2005\;scass
ellati\;;
1 ExplicitGroup:planning\;0\;lang2010\;;
1 ExplicitGroup:planning with rules\;0\;;
1 ExplicitGroup:pomdp based assistance\;0\;fern2010\;woodward2012\;fer
n2014\;;
1 ExplicitGroup:relational rl\;0\;tadepalli2004\;;
1 ExplicitGroup:sequences\;0\;;
1 ExplicitGroup:sgim\;0\;nguyen2014\;;
1 ExplicitGroup:social cues\;0\;vinciarelli2012\;calinon2008\;vinciare
lli2009\;salam2016\;nomikou2016\;lemme\;;
1 ExplicitGroup:social goal understanding\;0\;baker2008\;ullman2009\;b
aker2011\;pantelis2014\;baker2014\;diaconescu2014\;;
1 ExplicitGroup:structure learning\;0\;murphy2002\;tenenbaum2006\;nicu
lescu-mizil2007\;ghahramani1998\;;
1 ExplicitGroup:symbol grounding\;0\;taniguchi2015\;;
1 ExplicitGroup:teleological reasoning - goal directed\;0\;rolf2011\;l
utkebohle2009\;baranes2010\;pezzulo\;wrede2012\;peltason2010\;baranes2
013a\;peltason2009\;clark2013\;;
1 ExplicitGroup:temporal processing\;0\;lan2014\;koppula2016\;;
1 ExplicitGroup:tracking\;0\;wang2015\;;
1 ExplicitGroup:unsupervised deep learning\;0\;;
1 ExplicitGroup:variational inference\;0\;zotero-null-51\;;
1 ExplicitGroup:video prediction\;0\;vondrick\;lotter2015\;palm2012\;;
1 ExplicitGroup:virtual embodiment\;0\;kiela2016\;;
1 ExplicitGroup:virtual robotic simulation\;0\;inamura2010\;;
}

